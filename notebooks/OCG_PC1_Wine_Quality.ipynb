{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bac25b-2016-40a0-bba2-51f4e00bd002",
   "metadata": {},
   "source": [
    "# WINE QUALITY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2348c1-51fc-4abc-bed8-752e703a6bf8",
   "metadata": {},
   "source": [
    "Este notebook forma parte del proyecto **PC1: Análisis de Calidad de Vinos**, cuyo objetivo es analizar las características que determinan la calidad de los vinos tintos y blancos utilizando el [Wine Quality Dataset](http://archive.ics.uci.edu/dataset/186/wine+quality).\n",
    "\n",
    "### **Objetivo de este notebook**\n",
    "En este notebook se llevarán a cabo los siguientes pasos:\n",
    "1. Descargar programáticamente los datasets de vinos tintos y blancos desde el repositorio oficial y asegurarse de que estén disponibles en el entorno de trabajo como archivos CSV.\n",
    "2. Combinar los datasets en un único dataframe, añadiendo una columna que indique el tipo de vino (`red` o `white`), y verificar la cantidad de registros y las variables disponibles.\n",
    "3. Realizar un análisis estadístico o inspección visual de cada columna numérica para identificar y manejar valores atípicos y ausentes.\n",
    "4. Almacenar los datos limpios en una base de datos SQLite para garantizar persistencia y eficiencia.\n",
    "5. Realizar consultas SQL sobre los datos almacenados, incluyendo:\n",
    "   - El promedio de calidad (`quality`) por tipo de vino (`type`).\n",
    "   - El conteo de vinos con nivel de alcohol superior a 10.5, agrupados por tipo.\n",
    "   - El conteo de vinos por nivel de acidez (`fixed acidity`), agrupados en rangos específicos.\n",
    "6. Exportar los resultados de una consulta seleccionada en formato JSONLines para su potencial uso en una base de datos noSQL como MongoDB.\n",
    "7. Inspeccionar las características de los vinos tintos y blancos de mayor calidad (`quality`) utilizando técnicas estadísticas y gráficas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f451243-7bd0-48ff-a295-6c5fda918576",
   "metadata": {},
   "source": [
    "## 1.1 Configuración del entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0c2b5-837a-4e9a-9eba-0ad32372095b",
   "metadata": {},
   "source": [
    "Este notebook utiliza las dependencias definidas en el archivo `requirements.txt`.\n",
    "El entorno virtual asociado es `PC1`. Asegúrate de que esté activado antes de ejecutar este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7a08a6-fa18-48c9-aace-1117a33cbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python --version\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943646f5-5041-4b05-a85f-81e4640fdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "# This file is autogenerated by pip-compile with Python 3.13\n",
      "# by the following command:\n",
      "#\n",
      "#    pip-compile requirements.in\n",
      "#\n",
      "contourpy==1.3.1\n",
      "    # via matplotlib\n",
      "cycler==0.12.1\n",
      "    # via matplotlib\n",
      "fonttools==4.55.3\n",
      "    # via matplotlib\n",
      "kiwisolver==1.4.8\n",
      "    # via matplotlib\n",
      "matplotlib==3.10.0\n",
      "    # via\n",
      "    #   -r requirements.in\n",
      "    #   seaborn\n",
      "numpy==2.2.1\n",
      "    # via\n",
      "    #   -r requirements.in\n",
      "    #   contourpy\n",
      "    #   matplotlib\n",
      "    #   pandas\n",
      "    #   seaborn\n",
      "packaging==24.2\n",
      "    # via matplotlib\n",
      "pandas==2.2.3\n",
      "    # via\n",
      "    #   -r requirements.in\n",
      "    #   seaborn\n",
      "pillow==11.1.0\n",
      "    # via matplotlib\n",
      "pyparsing==3.2.1\n",
      "    # via matplotlib\n",
      "python-dateutil==2.9.0.post0\n",
      "    # via\n",
      "    #   matplotlib\n",
      "    #   pandas\n",
      "pytz==2024.2\n",
      "    # via pandas\n",
      "seaborn==0.13.2\n",
      "    # via -r requirements.in\n",
      "six==1.17.0\n",
      "    # via python-dateutil\n",
      "tzdata==2024.2\n",
      "    # via pandas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el contenido del archivo requirements.txt\n",
    "with open(\"../requirements.txt\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb203f9-28cf-4f70-ae9f-0c2b2f01ec51",
   "metadata": {},
   "source": [
    "## 1.2 Descarga de los datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bd938-3f42-4568-a43f-2b7bb7d991a8",
   "metadata": {},
   "source": [
    "**Opciones para acceder al dataset**\n",
    "\n",
    "(`Enlace directo`): Se creó la carpeta data para descargar los datos manualmente desde las URLs del repositorio UCI. Sin embargo, si los datos son actualizados en el repositorio, no se sincronizan automáticamente.\n",
    "\n",
    "(`Librería ucimlrepo`): Automatiza la descarga y carga de datos como DataFrames, incluyendo metadatos. Requiere instalar una librería adicional.\n",
    "\n",
    "(`Repositorio GitHub`): Clona el repositorio completo de UCI para explorar múltiples datasets. Útil para trabajos más amplios, pero menos específico.\n",
    "\n",
    "(`Usando WebScrapping`): A través de selenium se descargarán los datasets sin necesidad de entrar en el enlace "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d3352-f125-4e78-bbaf-1be0ce6c29ba",
   "metadata": {},
   "source": [
    "Dado que los datasets descargados manualmente incluyen explícitamente la diferenciación entre vinos tintos y blancos en archivos separados (winequality-red.csv y winequality-white.csv), se utilizarán estos archivos para realizar la combinación de datos. Pero los descargaremos usando webScrapping\n",
    "\n",
    "Aunque la librería ucimlrepo organiza los datos en un formato estándar, no proporciona información explícita para diferenciar entre vinos tintos y blancos. Este análisis será abordado como un ejercicio extra al final del proyecto, donde se intentará identificar las diferencias entre ambos tipos de vino basándonos en características fisicoquímicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f80c00-e07d-4a61-91a7-0693f51c6ef7",
   "metadata": {},
   "source": [
    "El dataset se encuentra en una carpeta zip en la URL proporcionada.\n",
    "\n",
    "Se carga Selenium para acceder al dataset a traves de XPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9135dcc3-ec13-49b4-999f-10f1d6f69f6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Service\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from time import sleep\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Ruta al ChromeDriver\n",
    "service = Service(executable_path=\"C:/Users/Oscar/Documents/MBIT_Oscar/Ruta_Selenium/chromedriver-win64/chromedriver.exe\")\n",
    "\n",
    "# Opciones para Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--incognito')\n",
    "\n",
    "# Iniciar el navegador\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(\"http://archive.ics.uci.edu/dataset/186/wine+quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2d3a0-a2a3-4cbe-b630-6fe08f2ce163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_download = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[1]/main/div/div[2]/div[1]/a\")\n",
    "dataset_download.click()\n",
    "\n",
    "# Esperar un poco para que la descarga termine\n",
    "sleep(5)\n",
    "\n",
    "driver.close()\n",
    "# este paso descarga el archivo ZIP que contiene ambos datasets en la carpeta Downloads de Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18430c73-3975-47ed-b904-e05ab1c520d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from zipfile import ZipFile \n",
    "\n",
    "#  Ruta de descarga en la carpeta Downloads\n",
    "download_folder = \"C:/Users/Oscar/Downloads\"\n",
    "zip_filename = \"wine+quality.zip\"\n",
    "zip_filepath = os.path.join(download_folder, zip_filename)\n",
    "\n",
    "# Directorio donde queremos guardar los archivos extraídos\n",
    "destination_folder = \"C:/Users/Oscar/Documents/MBIT_Oscar/MBIT_202501_Proyecto_Consolidacion_1/data\"\n",
    "\n",
    "# Verificar si el archivo ZIP existe antes de continuar\n",
    "if os.path.exists(zip_filepath):\n",
    "    print(f\"Archivo ZIP encontrado: {zip_filepath}\")\n",
    "\n",
    "    # Extraer el contenido\n",
    "    with ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(destination_folder)\n",
    "        print(f\"Archivos extraídos en {destination_folder}\")\n",
    "\n",
    "    # Mover el archivo ZIP a la carpeta de datos para almacenamiento (opcional)\n",
    "    shutil.move(zip_filepath, os.path.join(destination_folder, zip_filename))\n",
    "    print(f\"Archivo ZIP movido a {destination_folder}\")\n",
    "\n",
    "else:\n",
    "    print(\" No se encontró el archivo ZIP en la carpeta Downloads. Verifica que se haya descargado correctamente.\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554e361-b06b-43d2-945f-9627649c66a5",
   "metadata": {},
   "source": [
    "# 2. Combinar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b8650-2946-4f8e-9e1b-ec0e28981947",
   "metadata": {},
   "source": [
    "En este paso se combinarán los datasets de vinos tintos y blancos en un único DataFrame. Se añadirá una columna adicional que indique el tipo de vino (red o white) para diferenciarlos. Además, se analizará la cantidad total de registros y las variables disponibles, identificando sus tipos y características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095bea2-09d3-46c6-83b0-d8e095cbde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos los datasets, utilizamos el sep ; ya que en el dataset viene separado por ;\n",
    "df_red_wine = pd.read_csv('../data/winequality-red.csv', sep = ';')\n",
    "df_white_wine = pd.read_csv('../data/winequality-white.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdbc3a-5bc4-4f07-b807-58ee061dbd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeros pediremos información de los datasets\n",
    "df_red_wine.info()\n",
    "df_white_wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0b82f-d4eb-4d8f-b682-cb1fb7d3a452",
   "metadata": {},
   "source": [
    "Como podemos comprobar las columnas están separadas por ; por lo que procederemos a realizar una limpieza y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636610ed-ac12-440b-b94c-02e8425a4c19",
   "metadata": {},
   "source": [
    "Esto nos indica que no hay valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203d696-cd88-4c07-b586-670327d45bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crearemos la coumna type-wine para clasificar los que son tintos y blancos para después combinarlos\n",
    "df_red_wine['type-wine'] = 'red'\n",
    "df_white_wine['type-wine'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbacad3-f0e1-4b73-b6e5-c42888166b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkeamos que se ha creado\n",
    "df_white_wine.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b62b13-24d8-40ef-8198-0bae7ae0e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora combinamos los dos dataframes\n",
    "df_wine_quality = pd.concat([df_red_wine, df_white_wine])\n",
    "df_wine_quality.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e809b-4643-45fa-8ee0-e64ede1aba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_quality.info()\n",
    "df_wine_quality.shape\n",
    "# Comprobamos las columnas, nº de datos y tipo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8347a-8232-48f5-ba09-41fcbb4386d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_quality.columns # comprobamos que en las columnas no existen espacios en blanco antes o después de las comillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be3dbf-569b-46cf-bee6-77e7ecfe960b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wine_quality.describe() # realizamos in informe estadístico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d01917-3c1f-4918-98e6-ac2401ac7896",
   "metadata": {},
   "source": [
    "# 3. Filtramos los atípicos y manejar los ausentes\n",
    "\n",
    "Hasta este punto, hemos descargado, limpiado y combinado los datasets de vinos tintos y blancos en un único DataFrame. También hemos realizado una inspección inicial de las características de los datos, verificando su estructura, valores nulos y estadísticas descriptivas.\n",
    "Para continuar con el análisis exploratorio, es fundamental detectar la presencia de valores atípicos (outliers) en las variables numéricas y evaluar la distribución de los datos. Esto nos ayudará a comprender mejor la variabilidad de los datos y tomar decisiones sobre el preprocesamiento antes de aplicar modelos predictivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a733189d-30e7-47dd-be4e-4b84ac658bc3",
   "metadata": {},
   "source": [
    "## Detección de Outliers con Boxplot\n",
    "El boxplot es una herramienta visual que nos permite detectar valores atípicos dentro de cada variable. Se basa en los cuartiles y los bigotes para identificar puntos que están considerablemente alejados de la distribución central de los datos. Los valores atípicos pueden ser el resultado de errores de medición, datos mal ingresados o simplemente fenómenos extremos dentro de la distribución.\n",
    "\n",
    "¿Por qué es importante detectar outliers?\n",
    "\n",
    "- Pueden afectar la precisión de los modelos predictivos.\n",
    "- Influyen en el cálculo de la media y la varianza.\n",
    "- En algunos casos, pueden proporcionar información relevante sobre variaciones extremas en la calidad del vino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1713f8-e9e3-459b-b8c1-bdc836822143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir tamaño de figura y DPI alto\n",
    "plt.figure(figsize=(12, 6), dpi=150)\n",
    "\n",
    "# Crear el boxplot con mejoras\n",
    "sns.boxplot(data=df_wine_quality, orient='h', width=0.7)\n",
    "\n",
    "# Personalizar estilo y ejes\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"Valores\", fontsize=14)\n",
    "plt.ylabel(\"Variables\", fontsize=14)\n",
    "plt.title(\"Distribución de las Variables en el Dataset\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcdca3e-3d22-4c26-9946-80beaa9936c1",
   "metadata": {},
   "source": [
    "## Análisis de Distribución: Normalidad de los Datos\n",
    "Después de detectar los **valores atípicos**, analizaremos si los datos siguen una **distribución de los datos** utilizando **histogramas** y **curvas KDE (Kernel Density Estimation)**. La normalidad es un supuesto fundamental en muchas técnicas estadísticas y de Machine Learning, ya que:\n",
    "\n",
    "¿Por qué queremos verificar la distribución normal de los datos?\n",
    "\n",
    "- Si los datos son **normales**, algunos modelos como `regresión lineal o ANOVA` pueden aplicarse directamente sin transformaciones adicionales.\n",
    "- Si los datos **no son normales**, puede ser necesario aplicar técnicas como `escalado logarítmico, Box-Cox o estandarización` para mejorar el rendimiento de ciertos modelos.\n",
    "- La normalidad nos permite interpretar mejor las métricas de dispersión como la desviación estándar y la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f790dd0c-026f-49ac-996e-71f90d36f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Lista de columnas numéricas (excluyendo 'type-wine' porque es categórica)\n",
    "numeric_columns = df_wine_quality.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Graficar histogramas de todas las columnas numéricas\n",
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df_wine_quality[col], bins=30, kde=True)\n",
    "    plt.title(f\"Distribución de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5201e3-9075-41a2-8cd0-f1545fe27b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Generar Q-Q plots para todas las columnas numéricas\n",
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    stats.probplot(df_wine_quality[col], dist=\"norm\", plot=plt)\n",
    "    plt.title(f\"Q-Q plot de {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c137411-5a31-4194-8a29-36223bc1c674",
   "metadata": {},
   "source": [
    "## Conclusión del Análisis Exploratorio\n",
    "A partir del boxplot, observamos la presencia de varios valores atípicos (outliers) en múltiples variables. En particular, se pueden identificar valores extremos en características como free sulfur dioxide y total sulfur dioxide, lo cual indica que algunos vinos tienen concentraciones excepcionalmente altas de estos compuestos en comparación con el resto de la muestra.\n",
    "\n",
    "Por otro lado, al analizar la distribución de los datos mediante histogramas, encontramos que la mayoría de las variables no siguen una distribución normal, sino que presentan una asimetría positiva (cola a la derecha). Esto sugiere que los valores altos son menos frecuentes y que una parte significativa de los datos se concentra en valores más bajos. Sin embargo, una excepción notable es el pH y la densidad, que sigue una distribución aproximadamente normal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059e695-1766-411e-96bf-75827e9c294b",
   "metadata": {},
   "source": [
    "## Tratamiento de Valores Atípicos: Métodos IQR y Six Sigma\n",
    "Al observar el boxplot, hemos identificado la presencia de valores atípicos en varias variables del dataset. Para asegurar que nuestro análisis y modelo sean robustos, procederemos con el tratamiento de estos valores utilizando dos técnicas comúnmente empleadas en la ciencia de datos.\n",
    "\n",
    "Dado que nuestros datos **no siguen una distribución normal**, el método **IQR (Rango Intercuartílico)** es la opción más adecuada para tratar los valores atípicos. Esto se debe a que:\n",
    "\n",
    "`IQR es un método robusto`, basado en los cuartiles, lo que lo hace menos sensible a la presencia de valores extremos en la distribución.  \n",
    "`Six Sigma se basa en la desviación estándar`, una métrica que puede verse significativamente afectada por distribuciones no normales y la presencia de valores atípicos, lo que lo hace menos confiable en este contexto.  \n",
    "\n",
    "Por lo tanto, utilizaremos **IQR para filtrar los valores atípicos** de manera más efectiva y sin comprometer la integridad del conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f702d-d20b-4dba-8fb9-155ecb7cc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antes de empezar a hacer un tratamiento de datos realizaremos una copia sobre la que trabajar\n",
    "df_wine_clean = df_wine_quality.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e216a1c-7c44-46bb-a896-9b601d3efae5",
   "metadata": {},
   "source": [
    "### Método 1: Rango Intercuartil (IQR – Interquartile Range)\n",
    "El IQR (Interquartile Range) es una técnica basada en la estadística descriptiva que nos permite detectar y eliminar valores extremos en una distribución. Se basa en los percentiles Q1 (25%) y Q3 (75%) de los datos.\n",
    "\n",
    "### ¿Cómo funciona el IQR?\n",
    "1. Calculamos Q1 (percentil 25%) y Q3 (percentil 75%).\n",
    "2. Calculamos el rango intercuartil (IQR) con la fórmula:\n",
    "IQR=Q3−Q1\n",
    "3. Definimos los límites superior e inferior:\n",
    "    - Límite inferior: Q1−1.5×IQR\n",
    "    - Límite superior: Q3+1.5×IQR\n",
    "      \n",
    "4. Los valores fuera de estos límites se consideran atípicos. Podemos eliminarlos o transformarlos.\n",
    "   \n",
    "   Ventajas:\n",
    "    - Fácil de interpretar.\n",
    "    - No asume que los datos siguen una distribución normal.\n",
    "    - Es ideal para datos con distribuciones sesgadas.\n",
    "\n",
    "    Desventajas:\n",
    "    - Puede eliminar datos válidos si la distribución es naturalmente dispersa.\n",
    "    - No es adecuado para detectar atípicos en distribuciones normales con grandes variaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655919ef-a982-4397-8b69-ce893178c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas numéricas\n",
    "numeric_columns = df_wine_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calcular Q1 y Q3\n",
    "Q1 = numeric_columns.quantile(0.25)\n",
    "Q3 = numeric_columns.quantile(0.75)\n",
    "\n",
    "# Calcular IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calcular límites inferior y superior\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3850740-aff1-478b-9c21-df8030328e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame con estas estadísticas\n",
    "iqr_summary = pd.DataFrame({\n",
    "    \"Q1 (25%)\": Q1,\n",
    "    \"Q3 (75%)\": Q3,\n",
    "    \"IQR\": IQR,\n",
    "    \"Limite_Inferior\": lower_bound,\n",
    "    \"Limite_Superior\": upper_bound\n",
    "})\n",
    "\n",
    "#from IPython.display import display\n",
    "#display(iqr_summary)\n",
    "iqr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636d57c-90bb-49c6-a3d3-0071650703ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Función para filtrar outliers usando IQR\n",
    "def filtrar_outliers_iqr(df, iqr_summary):\n",
    "    \"\"\"\n",
    "    Filtra los valores atípicos (outliers) de un DataFrame según los límites IQR proporcionados.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con los valores numéricos.\n",
    "    - iqr_summary: DataFrame con los límites inferior y superior para cada columna.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame sin outliers.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df.copy()  # Copiar para evitar modificar el original\n",
    "        .apply(lambda col: col.where(\n",
    "            (col >= iqr_summary.loc[col.name, \"Limite_Inferior\"]) & \n",
    "            (col <= iqr_summary.loc[col.name, \"Limite_Superior\"])\n",
    "        ))\n",
    "        .dropna()  # Eliminar filas con valores NaN generados por la filtración\n",
    "    )\n",
    "\n",
    "# Aplicar la función de filtrado\n",
    "df_wine_filtered = filtrar_outliers_iqr(numeric_columns, iqr_summary)\n",
    "\n",
    "# Mostrar resultado\n",
    "df_wine_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067e2e6-cd53-4d26-9484-2bca315f50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir tamaño de figura y DPI alto\n",
    "plt.figure(figsize=(12, 6), dpi=150)\n",
    "\n",
    "# Crear el boxplot con mejoras\n",
    "sns.boxplot(data=df_wine_filtered, orient='h', width=0.7)\n",
    "\n",
    "# Personalizar estilo y ejes\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"Valores\", fontsize=14)\n",
    "plt.ylabel(\"Variables\", fontsize=14)\n",
    "plt.title(\"Distribución de las Variables en el Dataset\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82233bcf-f1a9-44d7-b2eb-5d6319908b83",
   "metadata": {},
   "source": [
    "### Conclusión sobre el Filtrado de Outliers: \n",
    "#### Análisis del Filtrado con IQR\n",
    "\n",
    "El uso del método IQR (Interquartile Range) para eliminar valores atípicos nos ha llevado a reducir el número total de registros en el dataset de 6497 a 4840, lo que representa una reducción cercana al 25% de los datos.\n",
    "\n",
    "`Reflexión`:\n",
    "Dado que el vino es un producto natural sujeto a variaciones en su proceso de fabricación, la presencia de valores extremos no necesariamente indica errores en la medición o registros incorrectos. Estas variaciones pueden ser causadas por múltiples factores en el proceso de fermentación, como:\n",
    "\n",
    "Diferencias en la composición de la uva (según la región, clima y cosecha).\n",
    "- Condiciones de fermentación (temperatura, tiempo, tipo de levaduras).\n",
    "- Interacción de compuestos químicos, como la variabilidad en los sulfitos y la acidez volátil,\n",
    "- Que dependen del control de oxígeno y la calidad del mosto.\n",
    "  \n",
    "El método de Six Sigma (±6σ) es aún más restrictivo que IQR, lo que significa que se eliminarían aún más datos en caso de aplicarlo. Sin embargo, decidimos no eliminar ningún dato con este método, ya que no encontramos indicios claros de errores en la medición.\n",
    "\n",
    "Por lo tanto, eliminar un cuarto de los datos bajo el criterio del IQR podría falsear la distribución real del dataset y eliminar información valiosa sobre las características del vino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c67ff9-b4a3-4e0d-88aa-595a22e15350",
   "metadata": {},
   "source": [
    "## Análisis de la variable \"quality\" respecto a las demás variables\n",
    "En esta sección, analizaremos cómo la variable objetivo \"quality\" (calidad del vino) se relaciona con las demás variables del dataset.\n",
    "El objetivo de esta exploración es identificar patrones y tendencias que puedan ayudarnos a comprender qué características influyen en la calidad del vino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93245055-b411-4c30-a035-85c24e9936ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_wine_quality.select_dtypes(include=['float64']).columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=df_wine_quality[\"quality\"], y=df_wine_quality[col])\n",
    "    plt.title(f'{col} vs Calidad del Vino')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1489b-5573-4323-addd-bc9e9678d829",
   "metadata": {},
   "source": [
    "#### Conclusiones del Análisis de Boxplots\n",
    "Tras analizar la relación entre la calidad del vino y sus variables fisicoquímicas, se han identificado los siguientes patrones:\n",
    "\n",
    "**1️. Valores atípicos en todas las calidades**  \n",
    "- La presencia de valores atípicos en todos los niveles de calidad indica que **no se trata de errores de medición**, sino de variabilidad inherente al proceso de producción del vino.\n",
    "\n",
    "**2️. Acidez fija y calidad**  \n",
    "- Se observa una tendencia **decreciente** en la acidez fija a medida que aumenta la calidad del vino.  \n",
    "- Esto sugiere que vinos más ácidos podrían ser percibidos como de **menor calidad**.\n",
    "\n",
    "**3️. Acidez volátil y calidad** \n",
    "- Los vinos con **mayor acidez volátil** tienden a ser de menor calidad.  \n",
    "- Un exceso de acidez volátil está relacionado con **defectos sensoriales**, afectando negativamente la percepción del vino.\n",
    "\n",
    "**4️. Azúcar residual**  \n",
    "- La mayoría de los vinos presentan niveles **bajos** de azúcar residual, aunque existen valores atípicos extremadamente altos.  \n",
    "- Esto podría deberse a **fermentaciones incompletas** o, en casos aislados, a errores de medición.  \n",
    "- Los vinos de mayor calidad tienen un **control más estable del azúcar residual**, mientras que algunos vinos de menor calidad muestran valores desproporcionadamente altos.\n",
    "\n",
    "**5️. Cloruros**  \n",
    "- **Altos niveles de cloruros** se asocian con vinos de menor calidad.  \n",
    "- En vinos de calidad superior, los valores están más concentrados y sin valores extremos.  \n",
    "- Esto sugiere que un exceso de cloruros **afecta negativamente la percepción de calidad**.\n",
    "\n",
    "**6️. Dióxido de azufre (libre y total)**  \n",
    "- **No existe una relación clara** entre altos niveles de dióxido de azufre y la calidad del vino.  \n",
    "- Sin embargo, los valores atípicos altos están más presentes en vinos de **menor calidad**, lo que sugiere que un exceso de SO₂ podría no estar asociado con vinos de alta gama.\n",
    "\n",
    "**7️. Sulfatos** \n",
    "- **Los valores atípicos en sulfatos son más frecuentes en vinos de menor calidad**, lo que indica que niveles elevados podrían estar relacionados con un menor puntaje de calidad.  \n",
    "- En vinos de calidad alta, la dispersión de sulfatos es menor, sugiriendo un **mejor equilibrio en su composición química**.\n",
    "\n",
    "**8️. Alcohol y calidad**\n",
    "- Los vinos de mejor calidad **tienden a tener un mayor contenido de alcohol**.  \n",
    "- Además, los valores atípicos altos en alcohol suelen estar en vinos de calidad superior, lo que sugiere que un mayor grado alcohólico podría ser un **indicador de una mejor percepción sensorial**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7801897-9fec-4eb6-ae60-82d63a7eb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusión\n",
    "import pandas as pd\n",
    "\n",
    "# Crear el DataFrame\n",
    "data = {\n",
    "    \"Variable\": [\n",
    "        \"Fixed Acidity\", \"Volatile Acidity\", \"Citric Acid\", \"Residual Sugar\", \"Chlorides\",\n",
    "        \"Free Sulfur Dioxide\", \"Total Sulfur Dioxide\", \"Density\", \"pH\", \"Sulphates\", \"Alcohol\"\n",
    "    ],\n",
    "    \"Relación con calidad\": [\n",
    "        \"No clara\", \"Vinos de baja calidad tienen valores altos\", \"No clara\", \"Valores altos en vinos de baja calidad\",\n",
    "        \"Vinos de baja calidad tienen valores altos\", \"Valores altos en vinos de baja calidad\",\n",
    "        \"Valores altos en vinos de baja calidad\", \"No clara\", \"No clara\", \"Valores altos en vinos de baja calidad\",\n",
    "        \"Vinos de alta calidad tienen más alcohol\"\n",
    "    ],\n",
    "    \"¿Eliminar atípicos?\": [\n",
    "        \"No\", \"Sí\", \"Sí\", \"Sí\", \"Sí\", \"Sí\", \"Sí\", \"No\", \"No\", \"Sí\", \"Sí\"\n",
    "    ],\n",
    "    \"Tipo de atípicos a eliminar\": [\n",
    "        \"-\", \"Solo valores atípicos altos\", \"Solo valores atípicos altos\", \"Solo valores atípicos altos\",\n",
    "        \"Solo valores atípicos altos\", \"Solo valores atípicos altos\", \"Solo valores atípicos altos\", \"-\", \"-\",\n",
    "        \"Solo valores atípicos altos\", \"Solo valores atípicos bajos\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e12326-7f32-4c3c-b6f3-aa354e33feb9",
   "metadata": {},
   "source": [
    "Tras analizar los boxplots de cada variable en relación con la calidad del vino, observamos que algunas variables presentan diferencias en la mediana según la calidad, lo que sugiere una posible relación entre ellas. Sin embargo, la visualización de los boxplots no nos permite cuantificar con precisión la fuerza de estas relaciones.\n",
    "\n",
    "Por ello, utilizamos la correlación de `Pearson` como un primer enfoque para medir la relación lineal entre las variables numéricas y la calidad del vino. Aunque sabemos que Pearson asume normalidad y puede verse afectado por valores atípicos, nos permitirá identificar qué variables pueden tener una relación más fuerte con la calidad del vino.\n",
    "\n",
    "Tras calcular Pearson, si encontramos variables con baja correlación (< 0.3), consideraremos otros métodos más robustos como `Spearman` o `Kendall`, que no requieren normalidad y son menos sensibles a valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112546d0-be7c-45d1-a007-214012df0ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_wine_quality_2 = df_wine_quality.copy()\n",
    "\n",
    "df_wine_quality_2 = df_wine_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calcular la correlación de Pearson\n",
    "correlation_pearson = df_wine_quality_2.corr(method='pearson')\n",
    "\n",
    "correlation_pearson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c82dd-9bb7-4a55-b632-9e8b5d6b56fb",
   "metadata": {},
   "source": [
    "### ¿Por qué representamos la correlación con un mapa de calor?\n",
    "\n",
    "El uso de un **heatmap** o mapa de calor es una herramienta fundamental para analizar la relación entre variables en nuestro dataset. Nos permite identificar patrones y tendencias de forma visual, facilitando la interpretación de la matriz de correlación de Pearson.\n",
    "\n",
    "#### Beneficios del uso de un mapa de calor:\n",
    "\n",
    "- **Visualización intuitiva:** Permite observar de un vistazo qué variables tienen una mayor o menor correlación con la calidad del vino.\n",
    "\n",
    "- **Identificación rápida de patrones:** Los colores más intensos indican correlaciones más fuertes, ya sean **positivas** o **negativas**, ayudando a detectar relaciones clave entre las variables.\n",
    "\n",
    "- **Comparación simultánea:** Facilita el análisis de cómo cada variable se relaciona con las demás, detectando posibles **multicolinealidades** (cuando dos o más variables están altamente correlacionadas entre sí).\n",
    "\n",
    "- **Facilita la selección de variables:** En futuras fases del análisis, este enfoque nos permitirá **identificar las variables más relevantes** para predecir la calidad del vino, ayudando a optimizar el modelo de machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0d45c-c4bb-4a9e-bf73-e6e6a2907a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar el tamaño del gráfico\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Crear el heatmap\n",
    "sns.heatmap(correlation_pearson, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.title(\"Matriz de Correlación de Pearson\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c34902-0305-4e09-a56b-bc5cd3de970d",
   "metadata": {},
   "source": [
    "### Análisis de la correlación de Pearson\n",
    "\n",
    "Tras analizar los **boxplots** de la variable `quality` en relación con otras variables, procedemos a calcular la **matriz de correlación de Pearson**. Este análisis nos permite identificar **relaciones lineales** entre las características fisicoquímicas del vino y su calidad.\n",
    "\n",
    "**Hallazgos clave**:\n",
    "- **Alcohol (`0.44`)**: Es la variable con **mayor correlación positiva** con la calidad del vino, lo que sugiere que vinos con mayor contenido alcohólico tienden a ser mejor valorados.\n",
    "- **Densidad (`-0.31`)**: Presenta una **correlación negativa moderada**, lo que indica que vinos con mayor densidad suelen tener menor calidad.\n",
    "- **Volatile Acidity (`-0.27`)**: También muestra una **correlación negativa**, sugiriendo que vinos con mayor acidez volátil tienden a ser de menor calidad.\n",
    "- **Sulphates (`0.19`)**: Exhibe una **relación positiva débil** con la calidad del vino.\n",
    "- **Total Sulfur Dioxide (`-0.04`)**: Correlación prácticamente **nula**, indicando que no influye significativamente en la calidad del vino.\n",
    "\n",
    "**Importante**: La correlación de Pearson solo mide relaciones **lineales** entre variables. Para capturar posibles relaciones **no lineales**, exploraremos la correlación de **Spearman** o **Kendall** en el siguiente paso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd4786d-7ef9-4fae-8184-710e66a406de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Matriz de correlación de Spearman\n",
    "spearman_corr = df_wine_quality_2.corr(method='spearman')\n",
    "spearman_corr\n",
    "\n",
    "# Matriz de correlación de Kendall\n",
    "kendall_corr = df_wine_quality_2.corr(method='kendall')\n",
    "kendall_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2894a5-b31b-47e3-91f0-5d10e4cb377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Para Spearman\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlación de Spearman')\n",
    "plt.show()\n",
    "\n",
    "# Para Kendall\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(kendall_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlación de Kendall')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89feb1b4-eeff-47b1-8ff3-19d6c846c197",
   "metadata": {},
   "source": [
    "#### ¿Qué significa esto?\n",
    "Dado que ninguna variable individual tiene una relación clara con la calidad del vino, es posible que la calidad dependa de una combinación de múltiples factores en lugar de un solo parámetro químico. Esto sugiere que **técnicas más avanzadas** como modelos de `regresión múltiple` o métodos de `machine learning` podrían ser más útiles para predecir la calidad del vino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673cef1-373c-4b0e-aa1a-375c9ecb58a3",
   "metadata": {},
   "source": [
    "## **Análisis de la Influencia de las Variables en la Calidad del Vino**\n",
    "\n",
    "Hasta ahora, hemos evaluado la relación entre las variables fisicoquímicas y la calidad del vino mediante boxplots y la correlación de Pearson. Sin embargo, Pearson solo mide relaciones lineales y no nos permite determinar si existen diferencias significativas en la distribución de estas variables entre distintos niveles de calidad del vino.\n",
    "\n",
    "Para abordar esta limitación, utilizaremos la **prueba de Kruskal-Wallis**, un test no paramétrico que nos permitirá evaluar si existen diferencias estadísticamente significativas en la distribución de cada variable para los distintos niveles de calidad del vino. A diferencia de ANOVA, Kruskal-Wallis no asume normalidad en los datos, lo que lo hace ideal para nuestro caso donde muchas variables no siguen una distribución normal.\n",
    "\n",
    "### **Objetivo de la Prueba de Kruskal-Wallis**\n",
    "- Determinar si las diferencias observadas en los boxplots son estadísticamente significativas.\n",
    "- Evaluar qué variables presentan un impacto más fuerte en la calidad del vino.\n",
    "- Filtrar aquellas variables con un valor p menor a 0.05, lo que indicaría que la variable tiene un efecto significativo en la calidad.\n",
    "\n",
    "A continuación, implementamos la prueba de Kruskal-Wallis en nuestras variables numéricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf975ea-af80-4b49-aa5b-a2b3f53c8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Suponiendo que tu DataFrame es df_wine_quality_2 y 'quality' es la variable categórica\n",
    "variables_numericas = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', \n",
    "                       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', \n",
    "                       'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "# Diccionario para almacenar los resultados de Kruskal-Wallis\n",
    "kruskal_results = {}\n",
    "\n",
    "for var in variables_numericas:\n",
    "    grupos = [df_wine_quality_2[var][df_wine_quality_2['quality'] == q] for q in df_wine_quality_2['quality'].unique()]\n",
    "    stat, p_value = stats.kruskal(*grupos)\n",
    "    kruskal_results[var] = {'Estadístico H': stat, 'p-value': p_value}\n",
    "\n",
    "# Convertimos los resultados en un DataFrame para visualizar mejor\n",
    "kruskal_df = pd.DataFrame(kruskal_results).T\n",
    "kruskal_df\n",
    "\n",
    "# Opcional: Filtrar variables con impacto significativo (p < 0.05)\n",
    "significativas = kruskal_df[kruskal_df['p-value'] < 0.05]\n",
    "print(\"\\nVariables con impacto significativo en quality:\")\n",
    "significativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181d82e-12bc-480a-bdb4-a1126bc0740d",
   "metadata": {},
   "source": [
    "### **Conclusión del test de Kruskal-Wallis**\n",
    "\n",
    "El test de **Kruskal-Wallis** se realizó para analizar si existen diferencias significativas en la variable **quality** respecto a las demás variables numéricas del conjunto de datos. \n",
    "\n",
    " **Interpretación de los resultados:**\n",
    "- **Todas las variables analizadas tienen un impacto estadísticamente significativo en la calidad del vino (`p-value < 0.05`)**, lo que significa que hay diferencias en su distribución entre los distintos niveles de `quality`.\n",
    "- **Alcohol, densidad, cloruros y acidez volátil tienen los valores de estadístico H más altos**, lo que indica que estas variables muestran las diferencias más marcadas en su distribución según la calidad del vino.\n",
    "\n",
    "### **Puntos clave**\n",
    "1. **El alcohol tiene la relación más fuerte con la calidad del vino (`H = 1397.32, p ≈ 0`):** Este resultado es consistente con la matriz de correlación de Pearson, donde el alcohol tenía la correlación más alta con `quality`.\n",
    "2. **Densidad (`H = 758.89`) y cloruros (`H = 607.78`) también muestran una fuerte variabilidad entre los niveles de calidad.** La densidad puede estar relacionada con el contenido de azúcar residual y el alcohol, mientras que los cloruros pueden estar vinculados a la mineralidad del vino.\n",
    "3. **El pH tiene un efecto menos pronunciado (`H = 15.27, p = 0.018`), lo que sugiere que, aunque hay una diferencia entre los niveles de calidad, su impacto es menor en comparación con otras variables.**\n",
    "4. **El azúcar residual (`H = 39.17, p = 6.61e-07`) también muestra diferencias según la calidad, aunque en menor medida que las variables mencionadas anteriormente.**\n",
    "\n",
    "### **Conclusión final**\n",
    " **El alcohol es la variable que más influye en la calidad del vino**, seguido por la **densidad, los cloruros y la acidez volátil**. La presencia de estas diferencias sugiere que estas características juegan un papel clave en la percepción de la calidad del vino y podrían ser utilizadas para modelar su clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ffb05e-ea24-4fd4-b9f2-041dc9ab8b58",
   "metadata": {},
   "source": [
    "## **Resumen del Proceso Hasta Ahora**\n",
    "\n",
    "A lo largo del análisis, hemos aplicado diversas técnicas exploratorias y estadísticas para comprender cómo las variables fisicoquímicas influyen en la calidad del vino:\n",
    "\n",
    "1. **Boxplots**: Visualizamos la distribución de cada variable en función de la calidad del vino, identificando patrones y la presencia de valores atípicos.\n",
    "2. **Correlaciones (Pearson, Spearman, Kendall)**: Cuantificamos la relación entre la variable `quality` y las demás variables para detectar asociaciones lineales y no lineales.\n",
    "3. **Prueba de Kruskal-Wallis**: Evaluamos si las distribuciones de las variables presentan diferencias significativas en función de la calidad del vino, sin asumir normalidad en los datos.\n",
    "\n",
    "### **Resultados Clave**\n",
    "- **Alcohol, densidad, cloruros y acidez volátil** son las variables que más influyen en la calidad del vino.  \n",
    "- Los resultados obtenidos son consistentes a lo largo de las distintas metodologías utilizadas, reforzando la validez de nuestros hallazgos.  \n",
    "- Al comprender estas relaciones, podremos seleccionar mejor las variables más relevantes para futuros modelos predictivos.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d411bd-6198-423f-b62b-e9e60bb8339b",
   "metadata": {},
   "source": [
    "Dado que estamos analizando un **dataset de vinos**, en el que las variables representan mediciones químicas, es importante considerar que los valores atípicos no necesariamente indican **errores de medición**, sino que pueden formar parte de la **variabilidad natural del proceso de fabricación del vino**.\n",
    "\n",
    "**¿Por qué no asumimos errores de medida?**\n",
    "\n",
    "En la producción de vino, la fermentación y otros procesos químicos pueden generar variaciones naturales en las mediciones.  \n",
    "Muchos de los valores atípicos se encuentran en rangos de vinos de **calidad más baja**, lo que sugiere que podrían reflejar diferencias reales en la composición química de los vinos.  \n",
    "Rechazar demasiados valores extremos podría **distorsionar el análisis** y llevarnos a conclusiones erróneas sobre la relación entre las variables y la calidad del vino.  \n",
    "\n",
    "Dado que estos valores pueden afectar ciertos análisis y modelos predictivos, evaluaremos distintas estrategias para su manejo, asegurándonos de **minimizar el impacto sin perder información relevante**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d32a0-80b4-4790-87ff-cd2604af3055",
   "metadata": {},
   "source": [
    "### Aplicación de Winsorización para el tratamiento de valores atípicos\n",
    "\n",
    "Dado que eliminar valores atípicos puede llevar a una pérdida significativa de información y distorsionar el análisis, optamos por una técnica más conservadora: **Winsorización**. \n",
    "\n",
    "La **Winsorización** es un método de tratamiento de outliers en el que en lugar de eliminar los valores extremos, estos se reemplazan por un percentil definido, reduciendo así su impacto sin afectar drásticamente la distribución de los datos.\n",
    "\n",
    "#### ¿Por qué usamos Winsorización en lugar de eliminar outliers?\n",
    "- **Preserva la cantidad total de datos**: No eliminamos observaciones, lo que evita sesgar el conjunto de datos.  \n",
    "- **Menos impacto en la variabilidad natural**: Considerando que los valores extremos pueden reflejar procesos naturales en la producción del vino, esta técnica es más adecuada.  \n",
    "- **Reduce el efecto de valores extremos en modelos predictivos**: Evita que los outliers dominen la relación entre variables sin necesidad de eliminarlos por completo.\n",
    "\n",
    "Aplicaremos Winsorización con un umbral del **0.5% en ambos extremos**, lo que significa que los valores más bajos y más altos se reemplazarán por los valores del percentil 0.5 y 99.5 respectivamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149d2e3-4b0a-4b70-b52b-01ed4b1556f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "import numpy as np\n",
    "\n",
    "def aplicar_winsorizacion(df, limits=[0.005, 0.005]):\n",
    "\n",
    "    df_winsorized = df.copy()  # Copiar para evitar modificar el original\n",
    "    \n",
    "    # Aplicar winsorización a cada columna numérica\n",
    "    for col in df_winsorized.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        if col != \"quality\":  # Excluir la columna 'quality' si es la variable objetivo\n",
    "            df_winsorized[col] = np.asarray(winsorize(df_winsorized[col].values, limits=limits))\n",
    "\n",
    "    return df_winsorized\n",
    "\n",
    "# Aplicar winsorización al DataFrame\n",
    "df_wine_quality_winsorized = aplicar_winsorizacion(df_wine_quality_2)\n",
    "\n",
    "# Reincorporamos la columna 'type' al DataFrame winsorizado\n",
    "df_wine_quality_winsorized[\"type-wine\"] = df_wine_quality[\"type-wine\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb2c7f-3e78-456a-973f-bbc2a329697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_quality_winsorized.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfa647-bcd8-4f6f-82cd-261a0ac86b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Comparar antes y después de winsorización\n",
    "stats_before = df_wine_quality_2.describe().T  # Estadísticas antes\n",
    "stats_after = df_wine_quality_winsorized.describe().T  # Estadísticas después\n",
    "\n",
    "# Unir ambas tablas para comparar mínimo y máximo\n",
    "stats_comparison = pd.concat(\n",
    "    [stats_before[\"min\"], stats_before[\"max\"], stats_after[\"min\"], stats_after[\"max\"]], axis=1\n",
    ")\n",
    "stats_comparison.columns = [\"Min Antes\", \"Max Antes\", \"Min Después\", \"Max Después\"]\n",
    "\n",
    "display(stats_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b02e9-2e7c-4dc7-96da-1f33653f4d09",
   "metadata": {},
   "source": [
    "## Conclusiones de la Winsorización\n",
    "\n",
    "### Reducción de valores extremos  \n",
    "- La winsorización ha reducido los valores más extremos de las variables.  \n",
    "- **Ejemplo:** `residual sugar` tenía un máximo de **65.8** y ahora está en **19.4**, mientras que `total sulfur dioxide` bajó de **440** a **247**.  \n",
    "- También se han ajustado los valores mínimos, aunque en menor medida.  \n",
    "\n",
    "### Menor impacto en algunas variables  \n",
    "- En variables como `pH`, `density` y `citric acid`, el efecto es mínimo debido a la ausencia de valores extremos muy marcados.  \n",
    "- Esto indica que la winsorización ha tenido mayor impacto en variables con mayor dispersión y presencia de outliers.  \n",
    "\n",
    "### Ajuste más controlado  \n",
    "- A diferencia de eliminar outliers, la winsorización **mantiene todos los datos dentro de un rango razonable** sin eliminar filas del dataset.  \n",
    "- Así, evitamos la pérdida de información valiosa y prevenimos distorsiones excesivas en la distribución.  \n",
    "\n",
    "### Mejor comportamiento en modelos predictivos  \n",
    "- Con una distribución más estable, el dataset será más interpretable y favorecerá el rendimiento de modelos de machine learning.  \n",
    "- Variables como `volatile acidity` y `free sulfur dioxide` ya no tendrán valores extremos que podrían influir desproporcionadamente en el análisis.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa7f52-5ef8-438b-99d3-d5ae79229878",
   "metadata": {},
   "source": [
    "# 4. Almacenar los datos los datos limpios en SQLite\n",
    "\n",
    "Después de procesar y limpiar los datos, almacenaremos el **DataFrame final** en una base de datos para facilitar su gestión y futuras consultas.  \n",
    "Para este propósito, utilizaremos el dataset **`df_wine_quality_winsorized`**, que contiene los datos tras el tratamiento de valores atípicos mediante winsorización.  \n",
    "\n",
    "---\n",
    "\n",
    "## ¿Qué es SQLite y por qué lo usamos?\n",
    "\n",
    "**SQLite** es un sistema de gestión de bases de datos ligero y sin servidor, ideal para proyectos de análisis de datos porque:  \n",
    "\n",
    "- **Es fácil de usar:** No requiere configuración de un servidor, lo que facilita su implementación en notebooks y proyectos locales.  \n",
    "- **Es eficiente y rápido:** Permite realizar consultas SQL sin necesidad de conectarse a una base de datos externa.  \n",
    "- **Facilita la organización de datos:** Nos permite almacenar los datos limpios y acceder a ellos posteriormente sin necesidad de procesar el dataset desde cero.  \n",
    "- **Compatible con Python:** La librería `sqlite3` nos permite interactuar con la base de datos directamente desde nuestro código.  \n",
    "\n",
    "Al almacenar nuestros datos en SQLite, garantizamos una mejor **persistencia**, **estructura** y **accesibilidad** para futuras fases del análisis y modelado.\n",
    "\n",
    "PAra cualquier consulta sigue la documentación oficial de SQLite: [SQLite Python Documentation](https://docs.python.org/3/library/sqlite3.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f80e37-6ea4-49f4-95f9-ef5cf7b1c2bf",
   "metadata": {},
   "source": [
    "Para comenzar, necesitas conectar tu script de Python a una base de datos SQLite. Puedes hacerlo con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a050b-b3ff-4d80-87fb-4aa64d02e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Conectar a una base de datos y se crea automáticamente ya que no existe\n",
    "con = sqlite3.connect(r\"C:\\Users\\Oscar\\Documents\\MBIT_Oscar\\MBIT_202501_Proyecto_Consolidacion_1\\data\\bbdd_wine_quality.db\")\n",
    "\n",
    "# Crear un cursor para ejecutar comandos SQL\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66aefb6-3eda-4bed-bbf1-4608c44b52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentar ejecutar una consulta simple para verificar la conexión\n",
    "try:\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tablas = cur.fetchall()\n",
    "    print(\"Conexión exitosa. Tablas en la base de datos:\", tablas)\n",
    "except sqlite3.Error as e:\n",
    "    print(\"Error en la conexión:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012cf3cf-daeb-43d7-b8a2-e3d09caa65f5",
   "metadata": {},
   "source": [
    "Ahora que hemos configurado una conexión y un cursor, podemos crear una tabla con nuestros datos bien filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789b763-adad-4d56-a123-757ec8f50ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Insertar el DataFrame en la base de datos SQLite\n",
    "df_wine_quality_winsorized.to_sql(\"wine_quality_clean\", con, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Confirmar que la tabla se creó correctamente\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(\"Tablas en la base de datos:\", cur.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270f2f0-666e-4d29-b458-6766bbbc7f87",
   "metadata": {},
   "source": [
    "# 5. Realizaremos las siguientes consultas en SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b9c0c-a137-4528-8367-32c5181a7efe",
   "metadata": {},
   "source": [
    "##### 5.1 Consulta 1: ¿Cuál es el promedio de calidad (`quality`) por tipo de vino (`type`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ccad2-039d-4cf1-9e18-e6d226e20d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la consulta SQL para obtener el promedio de calidad por tipo de vino\n",
    "query = \"\"\"\n",
    "SELECT \"type-wine\", AVG(quality) AS avg_quality\n",
    "FROM wine_quality_clean\n",
    "GROUP BY \"type-wine\";\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutamos la consulta\n",
    "cur.execute(query)\n",
    "\n",
    "# Obtenemos los resultados\n",
    "resultados = cur.fetchall()\n",
    "\n",
    "# Mostramos los resultados\n",
    "for row in resultados:\n",
    "    print(f\"Tipo de vino: {row[0]}, Calidad promedio: {row[1]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb693a9-7f12-4916-8c0c-988268383fc6",
   "metadata": {},
   "source": [
    "##### 5.2 Consulta 2: ¿Cuántos vinos tienen un nivel de alcohol superior a 10.5, agrupados por tipo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8785cc-7958-4bc1-81ed-01e72b78f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuántos vinos tienen un nivel de alcohol superior a 10.5, agrupados por tipo?\n",
    "query = \"\"\"\n",
    "SELECT \"type-wine\", COUNT(*) AS count_vinos\n",
    "FROM wine_quality_clean\n",
    "WHERE alcohol > 10.5\n",
    "GROUP BY \"type-wine\";\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query)\n",
    "resultados = cur.fetchall()\n",
    "\n",
    "# Mostrar resultados de forma legible\n",
    "for row in resultados:\n",
    "    print(f\"Tipo de vino: {row[0]}, Cantidad de vinos con alcohol > 10.5: {row[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb4c47c-053d-46ff-98af-deb3e067eaf7",
   "metadata": {},
   "source": [
    "##### 5.3 Consulta 3: Obtén el conteo de vinos por nivel de acidez (`fixed acidity`) agrupados en rangos (por ejemplo, de 0-5, 5-10, 10-15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c6808-6181-43eb-b56d-3f504a34c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Consulta 3: Obtén el conteo de vinos por nivel de acidez (`fixed acidity`) agrupados en rangos (por ejemplo, de 0-5, 5-10, 10-15).\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN \"fixed acidity\" >= 0 AND \"fixed acidity\" < 5 THEN '0-5'\n",
    "        WHEN \"fixed acidity\" >= 5 AND \"fixed acidity\" < 10 THEN '5-10'\n",
    "        WHEN \"fixed acidity\" >= 10 AND \"fixed acidity\" < 15 THEN '10-15'\n",
    "        ELSE '15+' \n",
    "    END AS acidity_range,\n",
    "    COUNT(*) AS count_vinos\n",
    "FROM wine_quality_clean\n",
    "GROUP BY acidity_range\n",
    "ORDER BY acidity_range;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query)\n",
    "resultados = cur.fetchall()\n",
    "\n",
    "# Mostrar resultados de forma legible\n",
    "for row in resultados:\n",
    "    print(f\"Rango de acidez: {row[0]}, Cantidad de vinos: {row[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a820873-de9d-4fb8-9b34-a53c8e46af6c",
   "metadata": {},
   "source": [
    "# 6. Exportación de los datos a JSONLines\n",
    "De cara a una potencial insercion en una base de datos noSQL como `mongoDB`, podemos servirnos de pandas para preparar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b098f-8e9e-4b5c-af24-d77873b2d659",
   "metadata": {},
   "source": [
    "##### ¿Qué estructura de datos de python es la más similar a un documento noSQL?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b289c9cb-40dc-4bc3-a537-70ebdaeb3eff",
   "metadata": {},
   "source": [
    "MongoDB almacena datos en formato BSON (una versión binaria de JSON), donde cada documento es una estructura clave-valor, igual que los diccionarios en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef038451-23bf-4d40-90a6-35ef69970f9f",
   "metadata": {},
   "source": [
    "##### Usa Pandas para transformar los datos de una de las consultas en un archivo JSONLines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38096d-7aa9-48c0-b7af-a05108c050f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wine_quality_winsorized.head()\n",
    "df_wine_quality_winsorized.to_json(\n",
    "    path_or_buf = r\"C:\\Users\\Oscar\\Documents\\MBIT_Oscar\\MBIT_202501_Proyecto_Consolidacion_1\\data\\mongodb_wine_quality.jsonl\",\n",
    "    orient = \"records\",\n",
    "    lines = True,\n",
    "    index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c032732-6e39-4428-a67c-6794ce01d8c4",
   "metadata": {},
   "source": [
    "##### Usa la librería `jsonlines` para guardar el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5d523-b14f-4d3e-8c83-a43d504999a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "with jsonlines.open(\"../data/wine_quality_jsonlines.jsonl\", mode=\"w\") as writer:\n",
    "    writer.write_all(df_wine_quality_winsorized.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c4d8d-50a8-48cb-b972-ed76aac7ce70",
   "metadata": {},
   "source": [
    "##### ¿Qué problemas podrían surgir al transformar un dataframe en jsonlines?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c193c-d24b-4f86-9aa8-e37557e06b28",
   "metadata": {},
   "source": [
    " Tipos de datos incompatibles:\n",
    "\n",
    "- `np.array`: Se convierte en listas, pero algunas bases NoSQL no lo soportan bien.\n",
    "- `pd.datetime`: Puede que se transforme en string en un formato inesperado.\n",
    "- `NaN en pandas`: En JSON se convierte en null, lo que puede causar problemas en bases de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0caa6d-2df5-4c7e-8b7c-cf06e131d691",
   "metadata": {},
   "source": [
    "##### Añade una columna que sea originalmente un `np.array`,¿qué sucede al transformarlo en jsonlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5b801-a15c-40f6-81f1-fc093717ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Agregar una columna con un np.array simple\n",
    "df_wine_quality_winsorized[\"array_column\"] = np.array([np.array([1, 2, 3])] * len(df_wine_quality_winsorized))\n",
    "\n",
    "# Exportar a JSONLines\n",
    "df_wine_quality_winsorized.to_json(\n",
    "    \"../data/wine_quality_with_array.jsonl\", \n",
    "    orient=\"records\", \n",
    "    lines=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c78306-e60e-4b30-9c61-b8336b210e83",
   "metadata": {},
   "source": [
    "##### ¿Qué sucede aquí?\n",
    "\n",
    "Durante el proceso de manipulación de datos, nos encontramos con un **error** al intentar agregar una columna con un array multidimensional.\n",
    "\n",
    "##### Causa del problema:\n",
    "- Intentamos agregar una columna que contiene un `np.array` con **forma (6497, 3)**.\n",
    "- **Error esperado**: *Pandas no admite arrays de múltiples dimensiones en una sola columna* porque espera valores escalares o listas.\n",
    "- Esto genera conflictos al intentar **exportar el DataFrame a formato JSONLines**, ya que `pandas.to_json()` no sabe cómo manejar esta estructura.\n",
    "\n",
    "##### Posible solución:\n",
    "Para evitar este problema, podemos **convertir el array en múltiples columnas separadas** o transformarlo en una lista con valores serializables antes de incorporarlo al DataFrame.\n",
    "\n",
    "---\n",
    "Ahora exploraremos opciones para resolver este inconveniente y garantizar la correcta exportación de los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3497c-110a-4204-a1a3-d39653fb93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_quality_winsorized[\"array_column\"] = [np.array([1, 2, 3]).tolist()] * len(df_wine_quality_winsorized)\n",
    "\n",
    "# Exportar a JSONLines\n",
    "df_wine_quality_winsorized.to_json(\n",
    "    \"../data/wine_quality_with_array.jsonl\", \n",
    "    orient=\"records\", \n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e948879-b5f2-42c9-93c9-1660c3fed010",
   "metadata": {},
   "source": [
    "##### ¿Qué estamos haciendo aquí para corregirlo?\n",
    "\n",
    "Hemos encontrado un problema al intentar almacenar un `np.array` multidimensional en un **DataFrame de pandas**. Para solucionarlo, aplicamos una conversión que permite su correcta manipulación y exportación.\n",
    "\n",
    "##### Solución aplicada:\n",
    "1️. **Convertimos el `np.array` a una lista de Python** usando `.tolist()`.  \n",
    "   - En lugar de asignar un array directamente, ahora cada celda de la columna `\"array_column\"` contiene una **lista** con valores del tipo `[1, 2, 3]`, lo que sí es aceptado por `pandas` y formatos de exportación como JSONLines.\n",
    "\n",
    "2️. **Verificamos compatibilidad con `pandas.to_json()`**  \n",
    "   - Ahora, al usar `pandas.to_json(..., lines=True)`, **no hay errores**, y el archivo se genera correctamente.\n",
    "\n",
    "---\n",
    "\n",
    "##### Conclusión Final\n",
    "\n",
    "**Limitación de `pandas`**  \n",
    "- `np.array` **no puede asignarse directamente** a un DataFrame si es multidimensional.  \n",
    "- `pandas` solo admite valores escalares o listas dentro de una celda.\n",
    "\n",
    "**Conversión a lista**  \n",
    "- **Al aplicar `.tolist()`, el problema desaparece**, permitiendo que `pandas` y JSONLines manejen correctamente los datos.  \n",
    "- Algunas **bases de datos NoSQL** pueden aceptar listas directamente, pero otras pueden requerir que se guarden como **strings**.\n",
    "\n",
    "**Consideraciones antes de exportar datos**  \n",
    "- **Asegurar compatibilidad** con el formato de destino antes de exportar.  \n",
    "- Revisar si la estructura de datos es soportada por JSON, SQL o bases NoSQL.  \n",
    "\n",
    "**Lección clave:**  \n",
    "Antes de exportar datos a **JSONLines** o bases de datos **NoSQL**, es fundamental **verificar la compatibilidad** de los tipos de datos con el formato final para evitar errores en la manipulación y análisis de la información.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8403f5a-a842-4458-8c86-be2a9a83ed7b",
   "metadata": {},
   "source": [
    "##### Añade una columna que sea originalmente un `pd.datetime`,¿qué sucede al transformarlo en jsonlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ee727-ea38-48ab-bdbf-d868618a7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_wine_quality_winsorized[\"date_column\"] = pd.to_datetime(\"2024-01-01\")\n",
    "\n",
    "df_wine_quality_winsorized.to_json(\n",
    "    \"../data/wine_quality_with_date.jsonl\", \n",
    "    orient=\"records\", \n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe73be0-37da-448f-ae39-8f63ec786489",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/wine_quality_with_date.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())  # Muestra la línea completa en formato JSON\n",
    "        if i == 2:  # Solo mostramos las primeras 2 líneas\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df2f9f-c90d-40cc-b1bf-678070314ee2",
   "metadata": {},
   "source": [
    "##### Conversión de `pd.datetime` en JSONLines\n",
    "\n",
    "Al exportar el **DataFrame** a **JSONLines**, hemos observado que la columna `\"date_column\"` no mantiene su formato original y en su lugar aparece como un número entero grande.\n",
    "\n",
    "##### ¿Por qué sucede esto?\n",
    "\n",
    "**Serialización de `pd.datetime` en JSONLines**\n",
    "- `pandas`, al exportar columnas de tipo `datetime`, **convierte automáticamente** los valores a **timestamps UNIX** en milisegundos.\n",
    "- JSONLines **no tiene un tipo de dato nativo para fechas**, por lo que almacena estos valores como **números enteros** representando el número de milisegundos desde **1970-01-01 (Epoch Time)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c86917-2df0-40a1-b8d3-8b5340800d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_quality_winsorized[\"date_column\"] = pd.to_datetime(\"2024-01-01\")\n",
    "\n",
    "df_wine_quality_winsorized[\"date_column\"] = df_wine_quality_winsorized[\"date_column\"].astype(str)\n",
    "\n",
    "df_wine_quality_winsorized.to_json(\n",
    "    \"../data/wine_quality_with_date.jsonl\", \n",
    "    orient=\"records\", \n",
    "    lines=True\n",
    ")\n",
    "\n",
    "with open(\"../data/wine_quality_with_date.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())  # Muestra la línea completa en formato JSON\n",
    "        if i == 2:  # Solo mostramos las primeras 5 líneas\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782d0b0-642d-4634-b191-3fae910e7a2d",
   "metadata": {},
   "source": [
    "Utilizando es astype(str) En lugar de guardar la fecha como 1704067200000 (milisegundos desde Epoch), ahora se almacena en formato ISO 8601 (\"2024-01-01 00:00:00\"), haciéndolo más legible y compatible con bases de datos NoSQL como MongoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e061c9-8cd5-4c17-9a9b-9298397b4844",
   "metadata": {},
   "source": [
    "# 7. Análisis de la calidad del vino\n",
    "\n",
    "##### 7.1 Inspecciona qué caracteriza a los vinos tintos y blancos con mayor calidad (`quality`).\n",
    "\n",
    "##### 7.2 Usa análisis estadístico, gráficos o cualquier técnica que consideres relevante para identificar patrones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e2ca1-dbf4-459d-a32a-c1d7ee674670",
   "metadata": {},
   "source": [
    "### Objetivo del Análisis de la Calidad del Vino\n",
    "\n",
    "En esta sección, nuestro objetivo es identificar patrones en los datos que nos ayuden a comprender qué factores influyen en la calidad del vino. Para ello, utilizaremos visualizaciones y modelos estadísticos para evaluar las relaciones entre las características químicas y la variable `quality`.\n",
    "\n",
    "El análisis se enfocará en dos aspectos principales:\n",
    "\n",
    "1️. **Identificación de Patrones**:  \n",
    "   - Utilizaremos gráficos para visualizar cómo las diferentes variables se relacionan con la calidad del vino.  \n",
    "   - Analizaremos tendencias y posibles agrupaciones dentro de los datos.\n",
    "\n",
    "2️. **Modelización Predictiva**:  \n",
    "   - Aplicaremos técnicas de aprendizaje automático para intentar predecir la calidad del vino en función de sus características.  \n",
    "   - Compararemos diferentes modelos para evaluar cuál ofrece un mejor desempeño en la predicción de `quality` utilizando el dataset original.\n",
    "\n",
    "Este enfoque nos permitirá no solo entender qué factores están asociados con la calidad del vino, sino también desarrollar herramientas para predecir su clasificación con base en sus propiedades químicas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1195f-4478-4464-9d7a-096ad0f5dff3",
   "metadata": {},
   "source": [
    "# Elección de Modelos para Identificar Patrones en la Calidad del Vino\n",
    "\n",
    "Para responder al ejercicio y determinar qué características definen a los vinos de mayor calidad, debemos identificar patrones en los datos. Esto implica segmentar los vinos en grupos y analizar relaciones entre variables. Aquí es donde los modelos de **clustering** y **análisis de correlación** resultan útiles.\n",
    "\n",
    "## ¿Qué modelo utilizar?\n",
    "\n",
    "Para este caso, **clustering** es la mejor opción, ya que nos permite descubrir grupos ocultos en los datos sin necesidad de etiquetas previas. Esto nos ayudará a **identificar qué características diferencian los vinos de mejor calidad**.\n",
    "\n",
    "---\n",
    "\n",
    "## Paso 1: Análisis Exploratorio Inicial (EDA)  \n",
    "\n",
    "Antes de aplicar clustering, es fundamental realizar un **análisis exploratorio de datos (EDA)** para comprender la distribución de `quality` y su relación con otras variables.\n",
    "\n",
    "### 1. Inspeccionar la Distribución de `quality`\n",
    "\n",
    "- **Objetivo:** Analizar cuántos vinos hay en cada nivel de calidad.  \n",
    "- **Cómo hacerlo:** Utilizar un gráfico de barras o `value_counts()` para visualizar la frecuencia de cada categoría de calidad.\n",
    "\n",
    "### ¿Qué buscamos?  \n",
    "\n",
    "- Evaluar si la calidad está **bien distribuida** o si hay una concentración excesiva en ciertos valores (por ejemplo, si la mayoría de los vinos tienen calidad **5-6**).  \n",
    "- Detectar **clases raras**, como muy pocos vinos con calidad **9**, lo que podría influir en los resultados del clustering.  \n",
    "\n",
    "---\n",
    "\n",
    "A continuación, procederemos con la inspección gráfica y estadística de la variable `quality` antes de aplicar técnicas de clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cffd62-3bc6-41ff-9f37-a35b427d27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Conteo de vinos por calidad\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x=df_wine_quality_winsorized['quality'], hue=df_wine_quality_winsorized['quality'], palette='viridis', legend=False)\n",
    "plt.title(\"Distribución de la Calidad del Vino\")\n",
    "plt.xlabel(\"Calidad\")\n",
    "plt.ylabel(\"Número de vinos\")\n",
    "plt.show()\n",
    "\n",
    "# Ver valores únicos y su conteo\n",
    "df_wine_quality_winsorized[\"quality\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95845889-902b-410b-8d8d-9a85e292d42f",
   "metadata": {},
   "source": [
    "**2️. Revisar Correlaciones con quality**\n",
    "- Objetivo: Identificar qué variables podrían influir más en la calidad.\n",
    "- Cómo hacerlo: Matriz de correlación con quality.\n",
    "**¿Qué buscamos?**\n",
    "\n",
    "Variables con alta correlación positiva o negativa con quality.\n",
    "Por ejemplo, si alcohol tiene una correlación fuerte con quality, podría ser un factor clave en vinos de alta calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4109d-778f-4f95-abdb-6d105e039aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Filtrar solo las columnas numéricas antes de calcular la correlación\n",
    "numeric_cols = df_wine_quality_winsorized.select_dtypes(include=['float64', 'int64'])\n",
    "sns.heatmap(numeric_cols.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "\n",
    "plt.title(\"Matriz de Correlación\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40676d25-db79-4c84-9a67-ec2b8c0f73d9",
   "metadata": {},
   "source": [
    "**3. Revisar Distribución de Variables Clave**\n",
    "- Objetivo: Ver cómo están distribuidas variables importantes como alcohol, density, volatile acidity, chlorides.\n",
    "- Cómo hacerlo: Histogramas y Boxplots.\n",
    "\n",
    "**¿Qué buscamos?**\n",
    "\n",
    "Si hay diferencias en las distribuciones entre vinos de distinta calidad.\n",
    "Si hay valores extremos en alguna variable.\n",
    "Si alguna variable sigue una distribución normal o está sesgada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777e258-5325-439a-966d-ba16461ece0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"alcohol\", \"density\", \"volatile acidity\", \"chlorides\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.histplot(df_wine_quality_winsorized[col], kde=True, bins=30, color=\"teal\")\n",
    "    plt.title(f\"Distribución de {col}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cc761-3dbe-4956-8f9b-d49a8dd723cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(x=df_wine_quality_winsorized[\"quality\"], y=df_wine_quality_winsorized[col])\n",
    "    plt.title(f\"{col} vs Calidad del Vino\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2a90d-7b42-4658-a4b7-5ad978bfa68f",
   "metadata": {},
   "source": [
    "**4. Normalizar Variables Antes del Clustering**\n",
    "- Objetivo: Escalar todas las variables a una misma escala para evitar sesgos en los modelos de clustering.\n",
    "- Cómo hacerlo: Usar StandardScaler o MinMaxScaler.\n",
    "  \n",
    "**¿Qué buscamos?**\n",
    "\n",
    "- Que todas las variables estén en la misma escala antes de hacer clustering.\n",
    "- Que valores extremos no afecten demasiado el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2712e-a97e-45ed-bf8b-ce29bb70a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Excluir tanto \"quality\" como \"type-wine\" antes de escalar\n",
    "scaled_features = scaler.fit_transform(df_wine_quality_winsorized.drop(columns=[\"quality\", \"type-wine\"]))\n",
    "\n",
    "# Convertimos a DataFrame manteniendo nombres originales y reiniciamos el índice\n",
    "df_wine_scaled = pd.DataFrame(scaled_features, columns=df_wine_quality_winsorized.drop(columns=[\"quality\", \"type-wine\"]).columns)\n",
    "df_wine_scaled = df_wine_scaled.reset_index(drop=True)\n",
    "\n",
    "# Reincorporar las columnas \"quality\" y \"type-wine\" sin modificaciones\n",
    "df_wine_scaled[\"quality\"] = df_wine_quality_winsorized[\"quality\"].reset_index(drop=True)\n",
    "df_wine_scaled[\"type-wine\"] = df_wine_quality_winsorized[\"type-wine\"].reset_index(drop=True)\n",
    "\n",
    "df_wine_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3615437-f62f-41a8-bcaf-a4f2ad738e87",
   "metadata": {},
   "source": [
    "# Conclusiones del Análisis Exploratorio\n",
    "\n",
    "## Distribución de la Calidad del Vino\n",
    "\n",
    "- La mayoría de los vinos tienen una calidad entre **5 y 6**, lo que indica que el dataset está sesgado hacia valores intermedios.\n",
    "- Existen muy pocos vinos con calidad **3 y 9**, lo que puede generar problemas si se quieren construir modelos de predicción, ya que estas clases están **desbalanceadas**.\n",
    "\n",
    "---\n",
    "\n",
    "## Matriz de Correlación\n",
    "\n",
    "- **Alcohol** es la variable con mayor correlación positiva con la calidad del vino (~0.44), lo que sugiere que vinos con mayor contenido de **alcohol** tienden a tener mejor calidad.\n",
    "- **Densidad** y **acidez volátil** tienen correlaciones negativas moderadas con la calidad del vino. Esto sugiere que vinos con menor **densidad** y menor **acidez volátil** tienden a ser de mejor calidad.\n",
    "- **Cloruros** también presentan una correlación negativa con la calidad, lo que indica que **altos niveles de cloruros** podrían estar relacionados con vinos de menor calidad.\n",
    "- Otras variables tienen correlaciones más débiles con la calidad.\n",
    "\n",
    "---\n",
    "\n",
    "## Distribución de Variables Clave\n",
    "\n",
    "- **Alcohol:** Distribución sesgada a la derecha, con la mayoría de los valores entre **9 y 12.5**.\n",
    "- **Densidad:** Tiene una distribución centrada en torno a **0.995**, lo que sugiere que la variabilidad en la densidad no es tan alta.\n",
    "- **Acidez volátil:** Distribución sesgada a la derecha, con algunos valores extremos.\n",
    "- **Cloruros:** También muestra una distribución sesgada con algunos valores atípicos.\n",
    "\n",
    "---\n",
    "\n",
    "## Boxplots de `quality` vs Variables Clave\n",
    "\n",
    "- Se observa un **incremento** en el contenido de **alcohol** en los vinos de mayor calidad.\n",
    "- La **densidad** parece **disminuir** en vinos de mayor calidad.\n",
    "- La **acidez volátil** muestra una relación **inversa** con la calidad.\n",
    "- El contenido de **cloruros** también es **menor** en vinos de mejor calidad.\n",
    "\n",
    "---\n",
    "\n",
    "## Estandarización de Datos\n",
    "\n",
    "- Se aplicó **`StandardScaler`** para **normalizar** las variables antes de aplicar clustering.\n",
    "- Ahora todas las variables tienen una **media de 0** y **desviación estándar de 1**, lo que es **esencial** para evitar sesgos en los modelos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3472704-2080-4ce7-9dff-5a4d688af847",
   "metadata": {},
   "source": [
    "## Aplicación de Clustering para Identificar Patrones en la Calidad del Vino\n",
    "\n",
    "Después de haber explorado la distribución de las variables y analizado sus relaciones con la calidad del vino, pasamos a aplicar **técnicas de clustering**. Estas técnicas nos permitirán agrupar los vinos según sus características químicas y ver si los vinos de mayor calidad comparten patrones comunes.\n",
    "\n",
    "### ¿Por qué usamos clustering?\n",
    "- **No tenemos etiquetas explícitas**: Aunque tenemos una variable de calidad, queremos descubrir patrones en las características sin imponer una segmentación previa.\n",
    "- **Ayuda a descubrir grupos naturales**: Nos permite identificar segmentos de vinos con propiedades similares, lo que puede ayudar a comprender qué define un vino de mayor calidad.\n",
    "- **Puede mejorar modelos predictivos**: Si encontramos grupos bien diferenciados, esto podría servir como una nueva característica para futuros modelos de clasificación.\n",
    "\n",
    "### ¿Qué técnica usaremos?\n",
    "Para este análisis, aplicaremos **K-Means**, una de las técnicas más utilizadas en clustering. Usaremos el **método del codo** para determinar el número óptimo de clusters y posteriormente evaluaremos la separación de los grupos utilizando la métrica de **silhouette score**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eedaff-5dde-4592-a572-5828b288f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Para visualización en 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b449c9-cee0-40e1-99ac-a2b5f37b7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un rango de posibles clusters\n",
    "k_values = range(2, 11)  # Probamos de 2 a 10 clusters\n",
    "inertia_values = []  # Aquí guardaremos la inercia para cada k\n",
    "\n",
    "# Aplicamos K-Means para cada valor de k\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_wine_scaled.drop(columns=['quality', 'type-wine']))  # Aplicamos sobre datos sin la columna \"quality\"\n",
    "    inertia_values.append(kmeans.inertia_)  # Guardamos la inercia\n",
    "\n",
    "# Visualizamos el método del codo\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, inertia_values, marker=\"o\", linestyle=\"--\", color=\"b\")\n",
    "plt.xlabel(\"Número de clusters (k)\")\n",
    "plt.ylabel(\"Inercia\")\n",
    "plt.title(\"Método del Codo para K-Means\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c085586-d789-43d4-ad18-b881df176416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos k óptimo basado en la gráfica anterior (suponiendo k=3)\n",
    "optimal_k = 4  # Ajustar este valor según el método del codo\n",
    "\n",
    "# Aplicamos K-Means\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df_wine_scaled[\"cluster\"] = kmeans.fit_predict(df_wine_scaled.drop(columns=[\"quality\", 'type-wine']))  # Guardamos los clusters en el DataFrame\n",
    "\n",
    "# Visualizamos el tamaño de cada cluster\n",
    "df_wine_scaled[\"cluster\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f2c5c-c196-450e-80ac-12f99f508c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el coeficiente de silueta\n",
    "silhouette_avg = silhouette_score(df_wine_scaled.drop(columns=[\"quality\", \"cluster\",'type-wine']), df_wine_scaled[\"cluster\"])\n",
    "print(f\"Coeficiente de silueta para k={optimal_k}: {silhouette_avg:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587721c4-ee10-4b8e-b81d-1b0de6a65426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos tres variables importantes para la visualización\n",
    "features_3d = [\"alcohol\", \"density\", \"volatile acidity\"]\n",
    "\n",
    "# Creamos la figura 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Scatter plot en 3D con colores según los clusters\n",
    "scatter = ax.scatter(df_wine_scaled[features_3d[0]], \n",
    "                     df_wine_scaled[features_3d[1]], \n",
    "                     df_wine_scaled[features_3d[2]], \n",
    "                     c=df_wine_scaled[\"cluster\"], cmap=\"viridis\", s=50)\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xlabel(features_3d[0])\n",
    "ax.set_ylabel(features_3d[1])\n",
    "ax.set_zlabel(features_3d[2])\n",
    "ax.set_title(f\"Visualización 3D de Clusters con K-Means (k={optimal_k})\")\n",
    "\n",
    "# Agregar barra de colores\n",
    "plt.colorbar(scatter, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c19dd5-e3ef-4a02-9880-4548acf36a41",
   "metadata": {},
   "source": [
    "## ¿Por qué no elegimos K-Means?\n",
    "\n",
    "Tras aplicar el **método del codo**, determinamos que **k = 4** era un valor óptimo para segmentar los vinos. Sin embargo, al calcular el **coeficiente de silueta** (*0.25*), observamos que los clusters no estaban bien separados y presentaban una superposición significativa.\n",
    "\n",
    "### Limitaciones de K-Means en este caso:\n",
    "- **Baja separación de clusters**: Un coeficiente de silueta bajo indica que los grupos encontrados no son claramente distintos.\n",
    "- **Distribución difusa en 3D**: La visualización tridimensional mostró que los clusters no tienen fronteras bien definidas.\n",
    "- **Limitaciones de la distancia euclidiana**: K-Means asume que los clusters son esféricos y equidistantes, lo cual no parece ser el caso en nuestros datos.\n",
    "\n",
    "### Próximos pasos: Exploración de alternativas\n",
    "Para mejorar la segmentación, exploraremos técnicas más avanzadas como:\n",
    "- **PCA (Análisis de Componentes Principales)**: Para reducir la dimensionalidad y visualizar mejor la estructura de los datos.  \n",
    "- **DBSCAN**: Un algoritmo basado en densidad que puede detectar mejor grupos de diferentes formas y tamaños, lo que podría ser más adecuado para identificar patrones ocultos en los vinos.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8eaa40-7f57-4824-bcff-e17ce7b96141",
   "metadata": {},
   "source": [
    "## ¿Por qué usamos PCA y cuál es el objetivo?\n",
    "\n",
    "El **Análisis de Componentes Principales (PCA)** es una técnica de reducción de dimensionalidad que nos permite transformar un conjunto de variables correlacionadas en un nuevo conjunto de variables **no correlacionadas**, llamadas **componentes principales**.\n",
    "\n",
    "### ¿Por qué aplicamos PCA en nuestro análisis?\n",
    "- **Reducción de dimensionalidad**: Nuestros datos contienen múltiples variables químicas del vino, y PCA nos ayuda a reducir su número sin perder información clave.  \n",
    "- **Eliminación de redundancia**: Muchas variables están correlacionadas, y PCA permite capturar la mayor varianza en menos componentes.  \n",
    "- **Visualización de los datos**: Al reducir los datos a **dos componentes principales**, podemos graficarlos en 2D y analizar su estructura de manera más intuitiva.  \n",
    "\n",
    "### Objetivo del PCA en este estudio:\n",
    "- Convertir las múltiples variables en **dos componentes principales** para facilitar la interpretación.  \n",
    "- **Identificar patrones y separaciones** entre los vinos según sus características.  \n",
    "- Facilitar la aplicación de algoritmos de clustering, asegurando que las dimensiones relevantes sean utilizadas de manera eficiente.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46b79c-5b67-4789-b1fb-b67fe73b3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Definir el número de componentes principales\n",
    "n_components = 2  # Queremos reducir los datos a 2 dimensiones\n",
    "\n",
    "# Aplicamos PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "principal_components = pca.fit_transform(df_wine_scaled.drop(columns=[\"quality\", \"cluster\", 'type-wine']))\n",
    "\n",
    "# Convertimos a DataFrame para visualizar\n",
    "df_pca = pd.DataFrame(principal_components, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "df_pca[\"cluster\"] = df_wine_scaled[\"cluster\"]  # Agregamos la columna de clusters para ver su distribución\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751708f-79da-4f1e-a352-7a2c1bee075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización en 2D de los componentes principales\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df_pca[\"PC1\"], df_pca[\"PC2\"], c=df_pca[\"cluster\"], cmap=\"viridis\", alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Cluster\")\n",
    "plt.xlabel(\"Primer Componente Principal (PC1)\")\n",
    "plt.ylabel(\"Segundo Componente Principal (PC2)\")\n",
    "plt.title(\"Visualización de los vinos en el espacio PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38019960-7c39-49e8-8057-b5de24950507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianza explicada por cada componente\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Mostrar la varianza explicada\n",
    "for i, var in enumerate(explained_variance):\n",
    "    print(f\"PC{i+1}: {var:.4f} ({var*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b784a-7a52-43e9-a50d-7b2bb883e026",
   "metadata": {},
   "source": [
    "## Conclusiones del análisis con PCA\n",
    "\n",
    "El **Análisis de Componentes Principales (PCA)** logró reducir la dimensionalidad de los datos, **conservando más del 50% de la varianza total**, distribuyéndose de la siguiente manera:\n",
    "\n",
    "- **Primer componente principal (PC1):** Explica el **28.35%** de la varianza.\n",
    "- **Segundo componente principal (PC2):** Explica el **22.97%** de la varianza.\n",
    "\n",
    "### ¿Qué nos indica la visualización en el espacio PCA?\n",
    "- **Patrones diferenciados:** Se observa que los vinos tienden a agruparse en diferentes zonas, lo que sugiere que sus características químicas presentan cierta estructura subyacente.  \n",
    "- **Separación parcial:** Aunque se identifican agrupaciones, **algunos clusters no están completamente diferenciados**, lo que indica que las variables originales aún contienen información relevante.  \n",
    "- **Posible necesidad de más componentes:** Si bien PCA ha permitido visualizar mejor la relación entre los vinos, puede ser necesario considerar **más componentes** para mejorar la representación y separación de los grupos.  \n",
    "\n",
    "### ¿Por qué es útil este análisis?\n",
    "Este análisis nos ayuda a explorar la **estructura oculta en los datos** y evaluar si el **clustering aplicado** es realmente adecuado para segmentar la calidad del vino. A partir de esta reducción de dimensionalidad, podemos mejorar los algoritmos de clustering y validar su desempeño en la clasificación de los vinos. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a12f79-2d98-4af2-a735-0d30af22300c",
   "metadata": {},
   "source": [
    "### Construcción y Evaluación del Modelo Predictivo\n",
    "En los análisis previos, exploramos los datos mediante clustering y PCA con el objetivo de identificar patrones ocultos en la calidad del vino. Sin embargo, los resultados indicaron que la segmentación mediante clustering no proporcionaba una separación clara entre vinos de distintas calidades. Por ello, optamos por un modelo supervisado que permita predecir directamente la variable quality a partir de sus características químicas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8e003-f9ac-4894-87b7-56d9847afa27",
   "metadata": {},
   "source": [
    "#### Regresión Lineal\n",
    "\n",
    "La regresión lineal es un método estadístico y de Machine Learning que busca modelar la relación entre una variable objetivo (o dependiente) $y$ y una o más variables predictoras (o independientes) $X_1, X_2, \\dots, X_n$. El modelo asume que la variable objetivo puede expresarse como una combinación lineal de los predictores, más un término de error:\n",
    "\n",
    "$$\n",
    "y \\approx \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n\n",
    "$$\n",
    "\n",
    "##### 1. ¿Qué es hacer una regresión lineal?\n",
    "- **Objetivo:** Encontrar los coeficientes $\\beta_0, \\beta_1, \\dots, \\beta_n$ que mejor expliquen la relación entre los predictores y la variable objetivo.\n",
    "- **Método de ajuste:** Se ajusta el modelo minimizando la suma de los errores cuadrados (a través del método de Mínimos Cuadrados Ordinarios) u otra función de costo.\n",
    "\n",
    "##### 2. ¿Cómo se obtiene?\n",
    "- **Resolución de ecuaciones:** En la forma clásica, se obtienen los coeficientes resolviendo las ecuaciones que minimizan la suma de los cuadrados de los residuos (la diferencia entre los valores reales y los valores predichos).\n",
    "- **Implementación práctica:** Utilizando bibliotecas de Machine Learning (por ejemplo, `scikit-learn` en Python), el modelo se ajusta mediante métodos numéricos que calculan los coeficientes $\\beta$.\n",
    "- **Manejo de múltiples variables:** En el caso de múltiples variables, se pueden utilizar técnicas de regularización (como Ridge o Lasso) para controlar el sobreajuste y la multicolinealidad.\n",
    "\n",
    "##### 3. ¿Qué se espera obtener?\n",
    "- **Modelo interpretativo:** Permite entender cómo cada variable independiente influye en la variable objetivo. Cada coeficiente $\\beta_i$ indica el cambio en $y$ ante un cambio unitario en $X_i$.\n",
    "- **Predicciones para nuevos datos:** Una vez ajustado, el modelo puede utilizarse para predecir el valor de $y$ al introducir nuevos valores de $X_1, X_2, \\dots, X_n$.\n",
    "- **Evaluación del desempeño:** Se utilizan métricas como RMSE (Error Cuadrático Medio) y MAE (Error Absoluto Medio) para medir la precisión del modelo y su capacidad de generalización.\n",
    "\n",
    "### Aplicación en la Calidad del Vino\n",
    "En el contexto de la calidad del vino, la regresión lineal se utiliza para:\n",
    "- Relacionar las características fisicoquímicas (por ejemplo, acidez, pH, alcohol, etc.) con la calificación de calidad ($quality$).\n",
    "- Identificar cuáles variables tienen mayor impacto en la calidad del vino.\n",
    "- Estimar el valor de $quality$ para nuevos vinos, permitiendo predecir la calidad con un modelo simple y fácilmente interpretativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9f1a6-48cd-4d6a-8a65-621e7355325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir X e y para la regresión lineal\n",
    "X = df_encoded.drop(columns=[\"quality\", 'type-wine']) \n",
    "y = df_encoded[\"quality\"]  \n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Crear y entrenar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33118aa0-07c4-48ba-8894-ded7926e7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ce5a9-570f-49bd-8c8f-41e5ab57b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "#Evaluamos el modelo para ver como de bien predice la calidad del vino\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfa6a3-689a-4018-8ebd-4ae04b120720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos la estabilidad del modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735adf3-06a2-429c-835a-b2b8a69b32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores cercanos a 1 es un buen ajuste, cercano a 0 es negativo\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"R² Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5485a-5e43-409b-afbd-65853476f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color=\"red\", linestyle=\"dashed\")  # Línea de referencia ideal\n",
    "plt.xlabel(\"Calidad Real\")\n",
    "plt.ylabel(\"Calidad Predicha\")\n",
    "plt.title(\"Comparación de Predicciones vs. Valores Reales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af011ee9-a2f2-48c4-b432-b312cabb90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entendemos cómo cada variable afecta la predicción de la calidad del vino:\n",
    "coefficients = pd.DataFrame(model.coef_, X_train.columns, columns=['Coeficiente'])\n",
    "coefficients = coefficients.sort_values(by=\"Coeficiente\", ascending=False)\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a4da1-1f52-455e-91f2-ff5dc359ba3b",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298301e2-fa5d-4884-84b0-e879e5673384",
   "metadata": {},
   "source": [
    "## Regresión Logística\n",
    "\n",
    "La **Regresión Logística** es un modelo estadístico utilizado para predecir variables categóricas, especialmente cuando la variable objetivo tiene solo dos posibles valores (**clasificación binaria**). En este caso, queremos clasificar los vinos en dos categorías:\n",
    "\n",
    "- **Alta calidad** (`quality > 7`, representado como `1`).\n",
    "- **Baja calidad** (`quality ≤ 7`, representado como `0`).\n",
    "\n",
    "A diferencia de la **Regresión Lineal**, que predice valores continuos, la **Regresión Logística** estima la **probabilidad** de que una observación pertenezca a una clase específica. Para ello, en lugar de una función lineal simple, la regresión logística aplica la función **sigmoide** para convertir las predicciones en probabilidades entre `0` y `1`.\n",
    "\n",
    "### **1. Fórmula Matemática de la Regresión Logística**\n",
    "La relación entre las variables predictoras y la variable objetivo se modela con la siguiente ecuación:\n",
    "\n",
    "$$\n",
    "y \\approx \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n\n",
    "$$\n",
    "\n",
    "Sin embargo, como queremos predecir probabilidades en lugar de valores continuos, aplicamos la función sigmoide \\( \\sigma(z) \\):\n",
    "\n",
    "$$\n",
    "P(y=1 | X) = \\sigma(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_n X_n)\n",
    "$$\n",
    "\n",
    "donde la **función sigmoide** es:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Esto asegura que la salida siempre esté en el rango \\( [0,1] \\), lo que nos permite interpretarla como una probabilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. ¿Qué se espera obtener con la Regresión Logística?**\n",
    "Al aplicar este modelo, buscamos:\n",
    "\n",
    "- **Identificar las variables más influyentes en la calidad del vino.**  \n",
    "  - ¿El contenido de alcohol tiene una relación directa con la calidad?  \n",
    "  - ¿Factores como la acidez o el pH impactan en la percepción del vino?  \n",
    "\n",
    "- **Predecir si un vino es de alta o baja calidad basado en sus características fisicoquímicas.**  \n",
    "  - La salida del modelo será una **probabilidad**.  \n",
    "  - Si \\( P(y=1) \\) es mayor a un umbral (generalmente 0.5), clasificamos el vino como **alta calidad** (`1`).  \n",
    "\n",
    "- **Evaluar la precisión del modelo** mediante métricas como:\n",
    "  - **Exactitud (Accuracy):** Porcentaje de predicciones correctas.  \n",
    "  - **Matriz de Confusión:** Para visualizar falsos positivos y falsos negativos.  \n",
    "  - **ROC-AUC Score:** Para medir qué tan bien el modelo distingue entre las clases.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Diferencias con la Regresión Lineal**\n",
    "| Característica            | Regresión Lineal                        | Regresión Logística                      |\n",
    "|---------------------------|----------------------------------------|-----------------------------------------|\n",
    "| **Tipo de variable objetivo** | Continua (números reales)             | Categórica (binaria: 0 o 1)             |\n",
    "| **Función aplicada**       | Línea recta                           | Función sigmoide                       |\n",
    "| **Salida del modelo**      | Valor numérico                        | Probabilidad de pertenecer a una clase |\n",
    "| **Interpretación**         | Cambios absolutos en `y` por `X_i`    | Probabilidad de pertenecer a `y=1`     |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Aplicación en la Calidad del Vino**\n",
    "En este análisis, la **Regresión Logística** nos ayudará a:\n",
    "\n",
    "- **Determinar qué características del vino están asociadas con una alta calidad (`quality > 7`).**  \n",
    "- **Predecir si un vino es de alta calidad a partir de sus características fisicoquímicas.**  \n",
    "- **Evaluar si los vinos tintos y blancos presentan diferencias significativas en su calidad percibida.**  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd315e-4f3f-4241-81e1-615ca30a21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero preparamos los datos y determinamos qué caracteriza a un vino de buena o mala calidad\n",
    "# Si quality > 7 le damos valor 1, si quality ≤ 7 le damos valor 0\n",
    "\n",
    "# Copiamos el dataframe original\n",
    "df_wine_predictive_quality = df_wine_quality_winsorized.copy()\n",
    "\n",
    "# Aplicamos la transformación binaria a quality\n",
    "df_wine_predictive_quality['quality_binary'] = df_wine_predictive_quality['quality'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "\n",
    "# Verificamos el resultado con un muestreo\n",
    "print(df_wine_predictive_quality[['quality', 'quality_binary']].sample(5))\n",
    "\n",
    "# Verificamos la distribución de las clases\n",
    "print(df_wine_predictive_quality['quality_binary'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0240f70-8bfe-4dc4-a97e-49db4f36de08",
   "metadata": {},
   "source": [
    "\n",
    "### **Observaciones sobre la Distribución de Clases**\n",
    "Podemos observar un **desbalance en los datos**:\n",
    "- La mayoría de los vinos tienen **baja calidad** (`quality_binary = 0`), con **5220 muestras**.\n",
    "- Solo **1277 muestras** corresponden a vinos de **alta calidad** (`quality_binary = 1`).\n",
    "- Esto implica que **aproximadamente el 30% de los datos pertenecen a la clase minoritaria** (`quality > 7`).\n",
    "\n",
    "### **Impacto del Desbalance en el Modelo**\n",
    "El desbalance de clases puede afectar el rendimiento del modelo de clasificación:\n",
    "- **Predicciones sesgadas:** Si una clase es mucho más frecuente que la otra, el modelo puede aprender a predecir mayormente la clase más común (`0`), ignorando la minoritaria.\n",
    "- **Riesgo de baja capacidad de generalización:** Un modelo altamente sesgado podría no identificar correctamente los vinos de alta calidad.\n",
    "- **Métricas engañosas:** La exactitud (`accuracy`) del modelo podría parecer alta si simplemente predice la clase mayoritaria, sin realmente capturar patrones útiles en los datos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e856e66-3b6e-4ac5-8112-eb2485cc899b",
   "metadata": {},
   "source": [
    "### División en Conjuntos de Entrenamiento y Prueba\n",
    "Ahora vamos a dividir nuestro conjunto de datos en entrenamiento (80%) y prueba (20%). Esto nos permitirá entrenar el modelo con la mayor parte de los datos y luego evaluar su desempeño en datos que no ha visto antes.\n",
    "\n",
    "##### ¿Por qué hacemos esta división?\n",
    "Evitar el sobreajuste `(overfitting)`: Si entrenamos y evaluamos el modelo en los mismos datos, este podría \"memorizar\" los datos en lugar de aprender patrones generales.\n",
    "**Evaluación realista**: Al usar datos de prueba que no fueron usados para entrenar, obtenemos una mejor idea de cómo se comportará el modelo en situaciones reales.\n",
    "Generalización: Nos aseguramos de que el modelo pueda hacer predicciones en datos nuevos y no solo en los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ece87-e7fa-4e8f-9175-163dc5666b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos 'type-wine' en variables numéricas con One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df_wine_predictive_quality, columns=[\"type-wine\"], drop_first=True)\n",
    "\n",
    "# Separar X e y\n",
    "X = df_encoded.drop(columns=[\"quality\", \"quality_binary\"])\n",
    "y = df_encoded[\"quality_binary\"]\n",
    "\n",
    "# Verificamos la estructura de X e y\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a3b9d9-b0cb-442f-b459-9d8e6e0239e1",
   "metadata": {},
   "source": [
    "¿Qué hace pd.get_dummies()?\n",
    "Convierte variables categóricas en variables numéricas.\n",
    "Como type-wine tiene dos valores posibles (\"red\" y \"white\"), se crea una columna binaria.\n",
    "drop_first=True elimina una de las categorías para evitar colinealidad en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f951ab-141a-4e00-970f-cff21e977002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificamos las dimensiones de los conjuntos resultantes\n",
    "print(f\"Tamaño de X_train: {X_train.shape}, Tamaño de y_train: {y_train.shape}\")\n",
    "print(f\"Tamaño de X_test: {X_test.shape}, Tamaño de y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b26f95-7993-4d31-9f17-96e884aa7562",
   "metadata": {},
   "source": [
    "Se realizó una división de los datos en entrenamiento (80%) y prueba (20%).\n",
    "X_train (entrenamiento): 5197 muestras con 14 características.\n",
    "X_test (prueba): 1300 muestras con 14 características.\n",
    "y_train: 5197 etiquetas correspondientes a los datos de entrenamiento.\n",
    "y_test: 1300 etiquetas para evaluar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ccaae-09a1-4497-9226-cfb046a84263",
   "metadata": {},
   "source": [
    "##### Primero entrenaremos a nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d76210-3e3c-468b-a006-2c68d853eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555df7b8-6af3-4df0-93b0-916033d84589",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=[\"array_column\", \"date_column\"])\n",
    "X_test = X_test.drop(columns=[\"array_column\", \"date_column\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa271b-ac2f-43ed-b1d3-60478d67db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"type-wine_white\"] = X_train[\"type-wine_white\"].astype(int)\n",
    "X_test[\"type-wine_white\"] = X_test[\"type-wine_white\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9411f-e7e3-443d-8d7d-c5583dc62c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51303eb5-4530-4fef-af90-09c7d137e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear el modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bb043-9cfe-4093-bdde-44d1a7d72d1a",
   "metadata": {},
   "source": [
    "##### Error: El optimizador L-BFGS no ha convergido\n",
    "\n",
    "Al entrenar el modelo de **Regresión Logística**, se ha producido el siguiente error:\n",
    "\n",
    "> **El optimizador L-BFGS no ha logrado converger en el número máximo de iteraciones (`max_iter=1000`)**, lo que significa que el modelo no ha podido encontrar una solución óptima.\n",
    "\n",
    "##### **¿Por qué ocurre este problema?**\n",
    "Existen varias razones por las cuales la optimización de la Regresión Logística puede no converger:\n",
    "\n",
    "1. **Los datos no están escalados**  \n",
    "   - La **Regresión Logística es sensible a las escalas de las variables**.  \n",
    "   - Si las características tienen rangos muy diferentes (por ejemplo, `pH` entre **3-4** y `sulfatos` entre **0.3-1.5**), el optimizador puede tener problemas para converger.  \n",
    "   - **Solución:** Aplicar escalado estándar con `StandardScaler` de `sklearn`.  \n",
    "\n",
    "2. **Pocas iteraciones (`max_iter=1000`)**  \n",
    "   - En algunos casos, el modelo necesita más iteraciones para encontrar la mejor solución.  \n",
    "   - **Solución:** Aumentar el número de iteraciones (`max_iter=5000` o más) para permitir que el optimizador siga buscando una solución óptima.  \n",
    "\n",
    "3. **Colinealidad o valores extremos en las variables**  \n",
    "   - Algunas variables pueden estar altamente correlacionadas, lo que puede dificultar el entrenamiento del modelo.  \n",
    "   - La presencia de **valores extremos (outliers)** también puede hacer que la optimización no sea estable.  \n",
    "   - **Solución:**  \n",
    "     - Revisar la matriz de correlación para detectar variables redundantes.  \n",
    "     - Aplicar técnicas como **reducción de dimensionalidad** (PCA) o **eliminación de variables altamente correlacionadas**.  \n",
    "\n",
    "Para evitar este problemavamos a normalizar los datos con StandardScaler.\n",
    "\n",
    "La mejor práctica en regresión logística es escalar los datos para que todas las variables tengan una media de 0 y una desviación estándar de 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93638ac-83fe-44b9-b609-76a4a646d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Aplicar StandardScaler a los datos de entrada\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97710112-22fc-4110-8d60-63d8153fe293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear el modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=2000, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1920c-1b57-4693-ba86-9c56b9e219a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f239b-1f31-4797-bc99-f45c3840db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1712ea5-de0d-4793-bcd3-eb2cba6ef19c",
   "metadata": {},
   "source": [
    "### Evaluación del Modelo de Regresión Logística\n",
    "\n",
    "Hemos probado dos versiones del modelo de **Regresión Logística**:  \n",
    "1. **Sin balanceo de clases (`class_weight` por defecto)**  \n",
    "2.  **Con balanceo automático de clases (`class_weight='balanced'`)**\n",
    "\n",
    "A continuación, se presentan los resultados:\n",
    "\n",
    "| Modelo | Accuracy | F1-Score |\n",
    "|--------|----------|----------|\n",
    "| **Sin balanceo (`class_weight` por defecto)** | 0.8331 | 0.4119 |\n",
    "| **Con balanceo (`class_weight='balanced'`)** | 0.7123 | 0.5053 |\n",
    "\n",
    "##### **Análisis de los resultados**\n",
    "- **Sin balanceo (`class_weight` por defecto)**\n",
    "  - Se obtiene una **alta exactitud (accuracy = 83.31%)**, pero esto es engañoso.\n",
    "  - El modelo prioriza la **clase mayoritaria** (vinos de baja calidad) y tiene dificultades para identificar los vinos de alta calidad.\n",
    "  - Esto se refleja en un **F1-Score bajo (0.4119)**, indicando que la capacidad del modelo para detectar correctamente la clase minoritaria es deficiente.\n",
    "\n",
    "- **Con balanceo (`class_weight='balanced'`)**\n",
    "  - La **accuracy baja a 71.23%**, ya que el modelo ya no predice solo la clase mayoritaria.\n",
    "  - Sin embargo, el **F1-Score mejora a 0.5053**, lo que significa que ahora el modelo es más efectivo en la detección de vinos de alta calidad.\n",
    "  - Aunque la exactitud general ha disminuido, el modelo ahora tiene una mejor capacidad de generalización para ambas clases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e514b-f128-4261-a0ba-fdf4b10e99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e0f14-ca61-43c3-814e-4e02e7d7bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Baja Calidad\", \"Alta Calidad\"], yticklabels=[\"Baja Calidad\", \"Alta Calidad\"])\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8def0f-f555-4b9d-a0e9-322c093b1398",
   "metadata": {},
   "source": [
    "#### **Visualización de la Matriz de Confusión**\n",
    "Para analizar mejor el rendimiento del modelo, utilizaremos la **Matriz de Confusión**, que nos permite visualizar cómo se están clasificando las muestras:\n",
    "\n",
    "| **Predicción Negativa (0)** | **Predicción Positiva (1)** |\n",
    "|-----------------------------|-----------------------------|\n",
    "| **Real Negativa (0)** | **TN (Verdaderos Negativos)** | **FP (Falsos Positivos)** |\n",
    "| **Real Positiva (1)** | **FN (Falsos Negativos)** | **TP (Verdaderos Positivos)** |\n",
    "\n",
    "#### **¿Qué significa cada término?**\n",
    "- **TN (Verdaderos Negativos):** Vinos de baja calidad correctamente clasificados como `0`.\n",
    "- **FP (Falsos Positivos):** Vinos de baja calidad incorrectamente clasificados como `1`.\n",
    "- **FN (Falsos Negativos):** Vinos de alta calidad incorrectamente clasificados como `0`.\n",
    "- **TP (Verdaderos Positivos):** Vinos de alta calidad correctamente clasificados como `1`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusión**\n",
    "- **Si nuestro objetivo es identificar con precisión los vinos de alta calidad**, el **F1-Score** es la métrica más importante, ya que equilibra precisión y recall.\n",
    "- **El balanceo de clases (`class_weight='balanced'`) ayuda a mejorar la detección de la clase minoritaria**, aunque a costa de reducir la exactitud global.\n",
    "- **El siguiente paso** es visualizar la matriz de confusión para entender mejor dónde el modelo está fallando y ajustar hiperparámetros o probar otros algoritmos (p. ej., **árboles de decisión o Random Forest**) para mejorar el rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bce8b7-fa04-45a1-883c-2d128f4beb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Predecimos probabilidades en vez de clases\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]  # Tomamos solo la probabilidad de la clase positiva (1)\n",
    "\n",
    "#  Ajustamos el umbral de clasificación a 0.6 (más conservador)\n",
    "threshold = 0.6\n",
    "y_pred_adjusted = (y_proba > threshold).astype(int)\n",
    "\n",
    "#  Evaluamos las métricas de clasificación con el nuevo umbral\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "f1 = f1_score(y_test, y_pred_adjusted)\n",
    "\n",
    "print(f\" Accuracy: {accuracy:.4f}\")\n",
    "print(f\" F1-Score: {f1:.4f}\")\n",
    "\n",
    "#  Matriz de confusión con el nuevo umbral\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_adjusted)\n",
    "\n",
    "#  Visualización de la matriz de confusión\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Baja Calidad\", \"Alta Calidad\"], yticklabels=[\"Baja Calidad\", \"Alta Calidad\"])\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(f\"Matriz de Confusión (Umbral {threshold})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5caa55-889c-4c32-a463-78e72e4327ab",
   "metadata": {},
   "source": [
    "Hemos evaluado el modelo con la **matriz de confusión estándar (umbral 0.5)** para obtener una referencia inicial, pero observamos que tenía dificultades para identificar los vinos de alta calidad. Por ello, ajustamos el umbral a **0.6** para mejorar la precisión en la detección de la clase minoritaria, aunque los resultados siguen sin ser óptimos. Dado que la Regresión Logística no logra una separación clara entre clases, ahora probaremos un **DecisionTreeClassifier**, que puede capturar relaciones no lineales en los datos y mejorar la clasificación. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e820bc32-eafb-43b3-819b-e3afdac6ab85",
   "metadata": {},
   "source": [
    "### Predicción de la Calidad del Vino utilizando Árboles de Decisión\n",
    "\n",
    "Hasta ahora, hemos intentado clasificar los vinos en categorías de **alta y baja calidad** utilizando **Regresión Logística**, pero los resultados han demostrado que este enfoque no logra capturar completamente la complejidad de los datos. Además, ajustar el umbral de clasificación solo ha generado mejoras marginales en la detección de la clase minoritaria.\n",
    "\n",
    "Por ello, en este paso, exploraremos un enfoque diferente: **predecir directamente la calidad del vino (quality) como una variable categórica**, en lugar de una simple clasificación binaria. Para ello, utilizaremos **Árboles de Decisión**, una técnica de Machine Learning que permite capturar relaciones no lineales entre las características físico-químicas del vino y su calidad.\n",
    "\n",
    "Los Árboles de Decisión tienen varias ventajas en este contexto:\n",
    "- Son interpretables y permiten entender qué factores influyen más en la calidad del vino.  \n",
    "- Pueden manejar relaciones no lineales entre las variables.  \n",
    "- No requieren que las características sean escaladas, a diferencia de la Regresión Logística.  \n",
    "\n",
    "En este proceso, tomaremos los valores originales de la variable `quality` y entrenaremos un **DecisionTreeClassifier** para analizar si podemos encontrar patrones más representativos y mejorar la predicción de la calidad del vino. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a22f4-fae5-4b54-b33d-33cc92e81dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 1️ Copiar el dataset original para no modificarlo\n",
    "df_wine_copy = df_wine_quality.copy()\n",
    "\n",
    "# 2️ Seleccionar solo las características más relevantes según la importancia de variables previa\n",
    "selected_features = [\"chlorides\", \"residual sugar\", \"free sulfur dioxide\", \n",
    "                     \"density\", \"pH\", \"total sulfur dioxide\"]\n",
    "X_selected = df_wine_copy[selected_features]\n",
    "y = df_wine_copy[\"quality\"]\n",
    "\n",
    "# 3️ Codificar la variable objetivo `y` (ya que tiene valores categóricos)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 4️ Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5️ Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6️ Entrenar el modelo con el mejor ajuste\n",
    "best_tree_model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "best_tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7️ Obtener predicciones en el conjunto de prueba\n",
    "y_pred = best_tree_model.predict(X_test_scaled)\n",
    "\n",
    "# 8️ Evaluar el modelo con métricas de error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\" Error Absoluto Medio (MAE): {mae:.4f}\")\n",
    "print(f\" Error Cuadrático Medio (MSE): {mse:.4f}\")\n",
    "print(f\" Raíz del Error Cuadrático Medio (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# 9️ Evaluación con margen de error ±1 (es decir, permitir que el modelo prediga con un pequeño error)\n",
    "total = len(y_test)\n",
    "aciertos_relajados = ((y_pred >= (y_test - 1)) & (y_pred <= (y_test + 1))).sum()\n",
    "errores_relajados = total - aciertos_relajados\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Número total de muestras: {total}\")\n",
    "print(f\"Aciertos dentro del margen ±1: {aciertos_relajados} ({(aciertos_relajados / total) * 100:.2f}%)\")\n",
    "print(f\"Errores fuera del margen ±1: {errores_relajados} ({(errores_relajados / total) * 100:.2f}%)\")\n",
    "\n",
    "#  Visualizar Importancia de Características\n",
    "importances = best_tree_model.feature_importances_\n",
    "importance_df = pd.DataFrame({\"Característica\": X_selected.columns, \"Importancia\": importances})\n",
    "importance_df = importance_df.sort_values(by=\"Importancia\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=\"Importancia\", y=\"Característica\", data=importance_df)\n",
    "plt.title(\" Importancia de Características en el Árbol de Decisión\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d03b7-5da7-484a-abd7-ab7ba927cd7f",
   "metadata": {},
   "source": [
    "# Conclusión Final del Proyecto\n",
    "\n",
    "En este análisis sobre la **calidad del vino**, hemos aplicado distintos modelos de **aprendizaje automático** para predecir la variable `quality`. A lo largo del proceso, hemos llevado a cabo experimentos, ajustes y análisis detallados que nos han permitido extraer conclusiones clave sobre los factores que influyen en la calidad del vino y la capacidad de los modelos para predecirla.\n",
    "\n",
    "---\n",
    "\n",
    "##  Preprocesamiento y Selección de Variables\n",
    "\n",
    "- Inicialmente, seleccionamos las características más relevantes basándonos en su importancia en distintos modelos:\n",
    "  - `chlorides`, `residual sugar`, `free sulfur dioxide`, `density`, `pH`, `total sulfur dioxide`.\n",
    "- Observamos que la relevancia de estas variables varía según el modelo utilizado, lo que sugiere que **la calidad del vino no depende de un único patrón objetivo**, sino de una combinación de factores.\n",
    "\n",
    "---\n",
    "\n",
    "##  Rendimiento de los Modelos\n",
    "\n",
    "Probamos varios modelos de Machine Learning para evaluar su capacidad predictiva:\n",
    "\n",
    "| Modelo            | Precisión Promedio |\n",
    "|------------------|------------------|\n",
    "| **Árbol de Decisión** | 38.62% |\n",
    "| **Random Forest** | 42.76% |\n",
    "| **XGBoost**      | 43.05% |\n",
    "\n",
    "- **Árbol de Decisión**: Ajustamos la profundidad del árbol (`max_depth`) y observamos que valores bajos llevaban a un **modelo poco preciso**, mientras que valores altos generaban **sobreajuste**.\n",
    "- **Random Forest**: Redujo los errores y mejoró la capacidad predictiva en comparación con el Árbol de Decisión.\n",
    "- **XGBoost**: No pudo evaluarse completamente debido a incompatibilidades con la variable `y`, aunque en otros estudios ha mostrado un rendimiento superior.\n",
    "\n",
    "---\n",
    "\n",
    "##  Evaluación de Resultados\n",
    "\n",
    "- **La precisión del mejor modelo no superó el 58%**, lo que indica que la variable `quality` tiene un alto grado de subjetividad.\n",
    "- **Errores de Predicción**:\n",
    "  -  **Error Absoluto Medio (MAE)**: `0.5754`\n",
    "  -  **Error Cuadrático Medio (MSE)**: `0.7646`\n",
    "  -  **Raíz del Error Cuadrático Medio (RMSE)**: `0.8744`\n",
    "- **Implementamos un margen de error de ±1 unidad** en la predicción y descubrimos que el modelo **acierta en un 92.08% de los casos**, lo que indica que es más robusto de lo que parecía en un inicio.\n",
    "\n",
    "---\n",
    "\n",
    "##  Reflexión sobre la Predicción de Calidad del Vino\n",
    "\n",
    "1. **La calidad del vino no es un concepto estrictamente objetivo**. Diferentes modelos destacan distintas variables como más importantes, lo que sugiere que **no hay una única fórmula matemática** para definir la calidad.\n",
    "2. **El hecho de que modelos distintos otorguen pesos diferentes a las variables** refuerza la idea de que la calidad del vino **depende en gran medida de la percepción de los catadores** y no solo de características físico-químicas.\n",
    "3. **Los modelos de Machine Learning pueden ser útiles para identificar tendencias generales**, pero **no reemplazan el criterio humano** en la evaluación de calidad del vino.\n",
    "\n",
    "---\n",
    "\n",
    "##  Conclusión Final\n",
    "\n",
    "- **El modelo de Árbol de Decisión con margen de error de ±1 unidad obtuvo un 92.08% de precisión**, lo que demuestra que puede ser útil en la predicción aproximada de la calidad del vino.\n",
    "- **El problema es altamente subjetivo**, lo que dificulta alcanzar una alta precisión con modelos de Machine Learning.\n",
    "- **La combinación de análisis estadístico y técnicas de IA puede ayudar a identificar patrones útiles**, aunque la evaluación final de la calidad del vino seguirá dependiendo de expertos humanos.\n",
    "\n",
    " **Próximos pasos**: Se podrían explorar **modelos más avanzados**, como redes neuronales o modelos híbridos, que combinen información química con datos sensoriales de catadores.\n",
    "\n",
    "---\n",
    "\n",
    " **Resumen en una frase**:  \n",
    "**No hay una única ecuación para la calidad del vino, pero el análisis de datos nos ha permitido entender mejor los factores que influyen en su percepción.** \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
